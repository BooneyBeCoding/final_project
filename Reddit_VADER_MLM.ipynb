{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dependencies\n",
    "from path import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#load VADER\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPVOTE so everyone sees we got SUPPORT</td>\n",
       "      <td>265029</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/sgoqy8nyt2e61.png</td>\n",
       "      <td>11825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-29 00:40:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GME YOLO update — Jan 28 2021</td>\n",
       "      <td>230844</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/opzucppb15e61.png</td>\n",
       "      <td>23532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-29 08:06:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...</td>\n",
       "      <td>204920</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>18318</td>\n",
       "      <td>LEAVE ROBINHOOD. They dont deserve to make mon...</td>\n",
       "      <td>2021-01-29 00:49:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GME YOLO update — Jan 27 2021 ----------------...</td>\n",
       "      <td>185949</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/a309gkm5yxd61.png</td>\n",
       "      <td>15495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 08:15:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can we all take a moment and appreciate the Mo...</td>\n",
       "      <td>184517</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>7105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 11:57:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   score       subreddit  \\\n",
       "0             UPVOTE so everyone sees we got SUPPORT  265029  wallstreetbets   \n",
       "1                      GME YOLO update — Jan 28 2021  230844  wallstreetbets   \n",
       "2  CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...  204920  wallstreetbets   \n",
       "3  GME YOLO update — Jan 27 2021 ----------------...  185949  wallstreetbets   \n",
       "4  Can we all take a moment and appreciate the Mo...  184517  wallstreetbets   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0                https://i.redd.it/sgoqy8nyt2e61.png         11825   \n",
       "1                https://i.redd.it/opzucppb15e61.png         23532   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         18318   \n",
       "3                https://i.redd.it/a309gkm5yxd61.png         15495   \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...          7105   \n",
       "\n",
       "                                                body                 date  \n",
       "0                                                NaN  2021-01-29 00:40:34  \n",
       "1                                                NaN  2021-01-29 08:06:23  \n",
       "2  LEAVE ROBINHOOD. They dont deserve to make mon...  2021-01-29 00:49:11  \n",
       "3                                                NaN  2021-01-28 08:15:35  \n",
       "4                                                NaN  2021-01-28 11:57:32  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data\n",
    "data = Path('Resources/reddit.csv')\n",
    "reddit_df = pd.read_csv(data)\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           object\n",
       "score            int64\n",
       "subreddit       object\n",
       "url             object\n",
       "num_comments     int64\n",
       "body            object\n",
       "date            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking DTypes\n",
    "reddit_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "investing         987\n",
       "stocks            985\n",
       "wallstreetbets    953\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at subreddit value counts\n",
    "subreddit = reddit_df.subreddit.value_counts()\n",
    "subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Please use this thread to discuss your portfolio, learn of other stock tickers, and help out users by giving constructive criticism.\\r\\n\\r\\nWhy quarterly?  Public companies report earnings quarterly; many investors take this as an opportunity to rebalance their portfolios.  We highly recommend you do some reading:  A list of [relevant posts & book recommendations.](https://www.reddit.com/r/stocks/wiki/index#wiki_relevant_posts_.26amp.3B_book_recommendations)\\r\\n\\r\\nYou can find stocks on your own by using a scanner like your broker's or [Finviz.](https://finviz.com/screener.ashx)  To help further, here's a list of [relevant websites.](https://www.reddit.com/r/stocks/wiki/index#wiki_relevant_websites.2Fapps)\\r\\n\\r\\nIf you don't have a broker yet, see our [list of brokers](https://www.reddit.com/r/stocks/wiki/index#wiki_brokers_for_investing) or search old posts.  If you haven't started investing or trading yet, then setup your [paper trading.](https://www.reddit.com/r/stocks/wiki/index#wiki_is_there_a_way_to_practice.3F)\\r\\n\\r\\nBe aware of [Business Cycle Investing](https://eresearch.fidelity.com/eresearch/markets_sectors/sectors/si_business_cycle.jhtml?tab=sibusiness) which Fidelity issues updates to the state of global business cycles every 1 to 3 months (note: Fidelity changes their links often, so search for it since their take on it is enlightening).  [Investopedia's take on the Business Cycle](https://www.investopedia.com/articles/investing/061316/business-cycle-investing-ratios-use-each-cycle.asp) and their [video.](https://www.investopedia.com/video/play/business-cycle/)\\r\\n\\r\\nIf you need help with a falling stock price, check out Investopedia's [The Art of Selling A Losing Position](https://www.investopedia.com/articles/02/022002.asp) and their [list of biases.](https://www.investopedia.com/articles/stocks/08/capital-losses.asp)\\r\\n\\r\\nHere's a list of all the [previous portfolio stickies.](https://www.reddit.com/r/stocks/search?q=author%3Aautomoderator+%22Rate+My+Portfolio%22+-+r%2FStocks+Quarterly+Thread&restrict_sr=on&include_over_18=on&sort=new&t=all)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               4\n",
       "[link](https://www.cnbc.com/2020/12/20/mcconnell-says-congress-has-agreed-to-900-billion-coronavirus-stimulus-deal.html?utm_content=Main&utm_medium=Social&utm_source=Facebook&fbclid=IwAR2uRFFTS_C1F32Pn2swO-ha4pde1W0MUJWq8RZywN_54slLZ-vuG98R7no#Echobox=1608504254)\\r\\n\\r\\nKEY POINTS\\r\\nCongress reached a deal Sunday on a $900 billion coronavirus relief package, according to Senate Majority Leader Mitch McConnell.\\r\\nLawmakers will move to vote on the proposal, along with a full-year government spending bill, as soon as Sunday night.\\r\\nMillions of Americans have awaited aid for months as Congress failed to agree on another plan to boost a health-care system and economy buckling under the weight of the pandemic.\\r\\n\\r\\nCongress reached a deal Sunday on a $900 billion coronavirus relief package, a long-delayed effort to boost an American health-care system and economy buckling under the weight of the pandemic.\\r\\n\\r\\nSenate Majority Leader Mitch McConnell, R-Ky., announced the agreement on a pandemic aid and full-year government spending bill. He did not delve into many details. Congressional leaders have not yet released text of the more than $2 trillion legislation, which they hope to pass in the coming hours.\\r\\n\\r\\nThe agreement follows months of sniping on Capitol Hill over how best to fight a once-in-a-century crisis. A new round of aid cannot come soon enough for the millions of Americans who have tried to scrape together enough money to afford food and housing.\\r\\n\\r\\nThe $900 billion coronavirus relief plan under negotiation on Capitol Hill was set to include direct payments of $600 to many adults. Some families were also expected to get $600 per child.\\r\\n\\r\\nThe proposal was set to put at least $300 billion into small business assistance including Paycheck Protection Program loans. It would also add a $300 federal unemployment supplement and temporarily keep in place pandemic-era programs that expanded unemployment insurance eligibility.\\r\\n\\r\\nIf those provisions expire the day after Christmas, 12 million people will lose unemployment benefits.\\r\\n\\r\\nThe measure was also set to put critical funding into the distribution of the two FDA-approved Covid-19 vaccines. Health-care workers and top government officials have started to receive shots, and widespread inoculation in the coming months will help the world to emerge from the pandemic’s shadow.\\r\\n\\r\\nThe rescue package was also set to send relief to hospitals, many of which have struggled to keep up with a flood of Covid-19 patients. It was also expected to put new money into education and transportation.\\r\\n\\r\\nAs lawmakers finally reach a deal, the help comes too late for the nearly 8 million people estimated to have fallen into poverty since June. Many in Congress say the proposal will not go nearly far enough to address the scope of the health and economic crisis.\\r\\n\\r\\nProgressives and some Republicans have pushed for larger direct payments and retroactive federal unemployment payments. A $600 weekly supplement that buoyed millions of jobless Americans in the early months of the pandemic expired over the summer, and it took Congress months to agree to reinstate it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               2\n",
       "We’ve all seen it parroted on every investing related thread in the history of Reddit- “time in the market beats timing the market”. But I feel like this phrase gets misused quite a lot, and I would like to take this boring workday of a Saturday to just show the power of what “time in the market” actually has. \\r\\n\\r\\n1. What “time in the market” means and what it doesn’t mean \\r\\n\\r\\nTime in the market means, basically, maintaining ownership of assets that either 1, typically appreciate in value over time (stocks, real estate, commodities, etc) or 2, that produce a steady, ideally increasing, stream of income (dividend paying stocks, a business, rental properties, debt, etc). By “time in the market” it means that ownership of these assets over long periods of time, as in years and decades, is the key to wealth accumulation. If you look at most wealthy person alive today and in history, they gained their wealth through assets. They accumulate assets and own them. \\r\\n\\r\\n“Time in the market” does NOT mean buying clearly overvalued hype stocks because “I’m in for the long term”. I’m not gonna say any because I don’t want the comments to just be arguing about whether or not tesla is overvalued, but I hope you get the idea. However this doesn’t mean to just let your cash sit on the sidelines “waiting for a crash”. Typically there is no reason to have all your net worth tied up in cash, as it is the only asset class guaranteed to lose value over time. \\r\\n\\r\\nRather, you should be in the middle: continuing to own assets you already own and being on the lookout for more, fairly valued ones. I promise you that you can find value out there if you look for it. Even then you don’t necessarily always have to be buying. Sometimes doing nothing is the best choice. \\r\\n\\r\\n2. You’re probably wasting your time (and money) \\r\\n\\r\\nIf you’re anticipating a crash, good luck. There have been 8 major crashes since the 1920’s: an average of one every 12 years. There have been flash crashes and small recession but these shouldn’t concern you at all. On the large scale, the market has trended up for most of its existence. What makes this time different, exactly? Bulls have a tendency to believe that this time is different, but bears can have the same mindset, especially  considering that the US has been in a bull market for most of its history. So what makes this time different? \\r\\n\\r\\nSure, we will enter a bear market eventually but the US market has never failed retest its highs. If you’re selling because you anticipate a “correction”, you’re just wasting your time and money. Corrections are a blip on the radar over time. They are normal, healthy and should be seen as a good thing, just the market breathing, per se; nobody actually thinks “stocks only go up and never go down”. \\r\\n\\r\\nOnce you gain real money, in the high six figures and up, taxes will really start to eat into you. Selling positions with the intent to buy back in after a correction is probably an unprofitable endeavor. Why pay a good chunk of your earnings in taxes just to buy back 10% cheaper, especially when the 10% drop may or may not happen when you expect it to? This ties in to the last paragraph of point one, sometimes it’s best to do nothing and just continue to hold, letting your money work for you. \\r\\n\\r\\n3. Generational wealth\\r\\n\\r\\nThis is my main point. The Rothschilds, for example, have been building an empire for almost 300 years. That is 300 years of compounding interest. One thing they have done is accumulate assets, not sell them. The wealthy families of the Netherlands have been passing down assets for almost 400 years. \\r\\n\\r\\nEven on a less grandiose scale, just look to this subreddit. You’ll notice a lot of the users with higher portfolio balances probably received a nice inheritance somewhere along the way. This isn’t a bad thing and shouldn’t be shamed. After all, isn’t that everyone’s goal, to pass their wealth into their children? Unfortunately, with inheritances, a huge majority of inherited wealth is lost by the third generation. When the younger generation doesn’t know how to properly manage wealth, they end up wasting it all instead of further building it up. \\r\\n\\r\\n4. Compound interest \\r\\n\\r\\nSome call it the eighth wonder of the world, and rightfully so. There is no reason to interrupt compound interest unnecessarily. I would hope that most people here are investing with the goal of attaining compound interest, and selling your compounding assets is a solid way to halt it. \\r\\n\\r\\n5. Dividends \\r\\n\\r\\nWhether or not you chase dividends, I think we can all agree that we get some form of dividends or income from our investments. Dividends really show their power after several years of ownership. Buffett, for example, gets a 40% annual return from dividends on his initial Coca Cola investment. Fourty percent! And he doesn’t even DRIP them. Why on earth would people get rid of their assets that have potential to give those kind of returns after some years of ownership is beyond me. If you do a dividend return calculator going back multiple decades, you’ll find that most dividend paying securities will have similar returns once you have mature ownership of them. \\r\\n\\r\\n6. On “timing the market”\\r\\n\\r\\nThis is probably a controversial one but I definitely don’t believe in just buying whatever tickers you want because “time in the market beats timing the market”. Like I said above, time in > timing because of generational wealth, compound interest and ownership. It doesn’t mean buying the hottest Reddit ticker because you’re in for the long term. Taking well assessed risks with positive and realistic upside is ideal. \\r\\n\\r\\nSpending time to make sure the investment you’re about to make is a good investment is smart. If spending a week or two assessing your decision is a way to “miss out on sick gains bro, it’ll go up another 50% before you buy”, it’s probably a FOMO stock and you shouldn’t be in in the first place. If patience is key, that means patience with buying is just as important as patience with holding. \\r\\n\\r\\nAt the end of the day I’m a believer in ownership. Looking through most of wealthy individuals of today and in history, they all had one thing in common: they maintained possession of assets. They don’t sell their portfolios because they’re scared of a crash, they don’t have their net worth in a savings account. They assume a little bit of managed risk and let their money work for them. \\r\\n\\r\\nI made this post because I have to work on a Saturday and have nothing going on, I hope you at least enjoyed it or disagree with it so we can have some discussion going.                                                                                                                                                                                                                                           2\n",
       "https://www.cnbc.com/2019/10/01/charles-schwab-is-eliminating-online-commissions-for-trading-in-us-stocks-and-etfs.html\\r\\n\\r\\n\"Charles Scwab said on Tuesday that it is ending commissions for online trading in U.S. stocks, exchange-traded funds and options. The changes will apply to securities on Canadian exchanges as well.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             2\n",
       "This is a selfish post because I'd actually like some high level discussion instead of shallow discussion of fad stocks.\\r\\n\\r\\nSo many of these posts are \"Give me fish\" when--if people are really serious about investing--posts should be \"How do I fish?\" related.\\r\\n\\r\\nFor example, how much importance do you put on the P/E ratio?  Does it differ by sector? Are there any instances where you'd disregard it?\\r\\n\\r\\nThat's just a hypothetical, but it's the kind of discussion that I'd absolutely love to see on this sub.  Not \"Which stock to invest in?\" or \"What do I do with my X amount of money?\" There's so much interesting content to think about and we seem to never touch upon any of it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              2\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ..\n",
       "“Sales of new energy vehicles (NEVs) more than doubled to 144,000 units last month. The NEV segment includes all-electric, hybrid and hydrogen fuel-cell vehicles. NEV sales increased for a fourth straight month, accelerating from a 68% gain in September and 26% in August.”\\r\\n\\r\\n“China electric car sales hit 121,000 in October, up 137% vs. a year earlier.”\\r\\n\\r\\nMentioned: TSLA, NIO, XPEV, LI, BYDDF\\r\\n\\r\\n[source](https://www.investors.com/news/electric-cars-china-sales-double-october-2020-tesla-trails/#)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
       "While I generally never pay attention to motley fool articles I was reading one the other day about how a small company is poised to make big moves, next big thing, blah blah. But now after it has tanked I cant seem to find those articles anywhere. They've clearly been removed. Did anyone else see this/is somehow able to find it? And to those who get advice/information from them do you feel that an action like this would undermine their credibility. It's one thing to publish dubious analysis, it's another to erase evidence of your mistakes. Yes/no wtf?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
       "*  $1.82 per share, adjusted, vs. $1.54 per share as expected by analysts, according to Refinitiv. \\r\\n*   $37.15 billion, vs. $35.72 billion as expected by analysts, according to Refinitiv. \\r\\n\\r\\nAdditionally, Microsoft reports Azure public cloud grew 48%, experts had projected somewhere around 44%.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
       "Disclaimer: **I'm still long GME** 💎🙌🏻 🚀🚀🚀\\r\\n\\r\\n**This is potentially a market manipulation conspiracy of the highest order, here is what potentially happened today with the crash:**\\r\\n\\r\\n**1)** Citadel conspires with Brokers (Who are dependant on citadel securities for their business) to **BAN the buying of GME stock**, but continue to **allow only selling** \\r\\n\\r\\n**2)** Hedge funds or Citadel use high frequency trading algorithms to **artificially create downwards pressure on the stock price** through increasingly lower bids (Faked market movement transactions between two parties to themselves or an intermediary) - \\r\\n\\r\\n❗❗❗**This strategy is only possible due to low volume, and low volume is created because INVESTORS LITERALLY CANT BUY THE STOCK BECAUSE BROKERS BANNED BUYING IT**❗❗❗\\r\\n\\r\\n**3)** **Most Retail investors are unable to buy the now highly discounted shares during the crash**, they are only able to sell or buy in when the crash is already over and shorts covered. People see that the stock price went from 450$ to 150$ and a mass selloff panic makes a bunch of people sell their stock. Frequent halts only allow for 10-15s of selling on the way down increasing panic.\\r\\n\\r\\n**4)** **SINCE RETAIL INVESTORS CANT BUY ANY GME STOCK, WHO BUYS ALL THESE PANIC SOLD GME SHARES? FUCKING HEDGE FUNDS THATS WHO**, every stock sold during the drop and at the bottom is not bought by normal investors, its bought by hedge funds to cover their shorts\\r\\n\\r\\n**5)** Hedge funds cover their shorts on the way to the bottom at 120$ closing their positions at a lower loss. \\r\\n\\r\\n**6)** Now they buy call options and stop manipulating the stock price downwards, natural market forces create a bounce making their calls worth more -> they sell these calls immediately to recoup further losses made on their shorts\\r\\n\\r\\n**7)** Hedge funds successfully exited their positions at a  much lower loss at the bottom of the crash or highly reduced their losses. \\r\\n\\r\\n**8)** If they're ever bigger greedy fucks **Hedge funds can now RE-BORROW shares at fucking dirt-cheap prices** now that they've neutrally closed their heavily in the red positions and repeat the same thing again, or just not get back in the game\\r\\n\\r\\n-------------------------\\r\\n\\r\\n**SOME BIG PLAYERS THAT ARE POTENTIALLY BEHIND THIS MARKET MANIPULATION ARE MOST LIKELY OUT OF THEIR MOST DANGEROUS NAKED SHORTS, THIS DOES NOT MEAN THAT SHORT % HAS DECREASED THOUGH, IT COULD BE REPLACED BY NEW SHORTS FROM OTHER HEDGE FUNDS ETC. .**\\r\\n\\r\\nThe one holding the bag in the end wont be Melvin or Citadel, it'll be random retail investors and smaller funds.\\r\\n\\r\\n\\r\\n-----------------\\r\\n\\r\\n**This is clearly a parody, all similarities with real life situation is purely a coincidence, I don't want to get sued**\\r\\n\\r\\n-----------------\\r\\n\\r\\n**EDIT 0:**\\r\\n\\r\\n❗❗❗❗❗❗❗❗❗**OKAY AGAIN FOR THE RETARDS IN THE BACK** ❗❗❗❗❗❗❗❗❗\\r\\n\\r\\n**Q:WHY TOTAL SHORTS ARE STILL OVER 100%, BUT SOME BIG PLAYERS PROBABLY ALREADY COVERED**\\r\\n\\r\\n**THERE ->IS NOT<- ONLY 1 PERSON/FUND/INSTITUTION SHORTING 100%+ OF THE STOCK. ITS HUNDREDS OF HEDGE FUNDS AND INVESTORS AND INSTITUTIONS. THE SHORTS COULD DECREASE BY 5% AND THATS ENOUGH FOR A BIG EXIT FOR SOME PLAYERS, LIKEWISE 10% OF OLD SHORTS COULD EXIT, AND 20% NEW SHORTS WOULD ENTER AND SHORT AND THE SHORTED FLOAT WOULD GO UP 10% WHILE STILL ALLOWING OLD SHORTS TO EXIT THEIR POSITIONS, SHORT FLOAT STAYING THE SAME OR INCREASING DOESNT MEAN THAT SOME HEDGE FUNDS DIDNT CLOSE THEIR OLD EXTREMELY RISKY POSITIONS**\\r\\n\\r\\n**IM NOT SAYING THAT THE ENTIRE SHORT POSITION ON GAMESTOCK IS CLOSED. ITS NOT, IT'S STILL OVER 100% I'M JUST SAYING THAT A FEW SPECIFIC !BIG! PLAYERS WHO WERE SHORT MOST LIKELY EXITED THEIR MOST RISKY SHORT POSITIONS BY POTENTIALLY ARTIFICIALLY CREATING THE CONDITIONS FOR A CRASH**\\r\\n\\r\\n**IF A FEW HEDGE FUNDS SHORTED A FEW SMALL % OF THE TOTAL FLOAT AND COVERED AT THE BOTTOM OF TODAYS CRASH THE TOTAL FLOAT SHORTED WOULDN'T CHANGE MUCH BUT A FEW KEY PLAYERS COULD BE OUT OF THEIR POSITIONS, LIKEWISE NEW SHORTS COULD BE REPLACING OLDER ONES WITH CHEAPER SHORTS**\\r\\n\\r\\n-------------------------\\r\\n\\r\\nEdit1:\\r\\n\\r\\n**FURTHER ASK YOURSELF:**\\r\\n\\r\\n**IF CITADEL AFFILIATED STOCK BROKERS WERE REALLY PROTECTING RETAIL INVESTORS DUE TO \"RISK\" WHY DIDNT THEY BAN BUYING AND SELLING?** \\r\\n\\r\\n**THEY BANNED BUYING ONLY, HELPING THEIR HEDGE FUND BUDDIES DRIVE THE PRICE DOWN TO COVER SHORTS**\\r\\n\\r\\n**AND ONLY RETAIL INVESTORS WERE BANNED FROM BUYING, HEDGE FUNDS COULD STILL BUY NORMALY**\\r\\n\\r\\n**MEANING THAT THE HEDGE FUNDS HAD FIRST PICK ACCESS TO BUY THE SHARES TO COVER THEIR SHORTS, THESE SAME SHARES WOULD NORMALLY BE BOUGHT BY RETAIL INVESTORS MAKING IT MORE EXPENSIVE FOR SHORTS TO COVER**\\r\\n\\r\\n__________________________________________________________\\r\\n\\r\\nEdit2:\\r\\n\\r\\n**SHORTED STOCK % MIGHT NOT CHANGE MUCH DUE TO EITHER NEW SHORTS BUYING IN, OR OLD SHORTS NOW SHORTING IN A MUCH CHEAPER WAY - NOW THAT THEY GOT RID OF THEIR MOST DANGEROUS SHORT POSITIONS**\\r\\n\\r\\n**ALL SHORTS MIGHT NOT BE CLOSED, BUT THIS MARKET MOVE WAS ARTIFICIALLY CREATED TO COVER AT MINIMUM THE MOST OVER-LEVERAGED AND RISKY SHORT POSITIONS THESE FUNDS TOOK ON THEMSELVES**\\r\\n\\r\\n___________________________________________________________\\r\\n\\r\\nEDIT3:\\r\\n\\r\\n**THE PRICE CRASHED ALMOST 400$ ON LIKE 10%-20%  OF THE USUAL TRADING VOLUME, DOES THIS LOOK LIKE \"NATURAL\" MARKET BEHAVIOUR TO YOU?**\\r\\n\\r\\n**IF THIS WAS A NATURAL STOCK CRASH THE VOLUME WOULD BE RELATIVELY HIGH, BUT INSTEAD THE STOCK PRICE DROPPED 70-80% ON 1/10TH OF USUAL TRADING VOLUME. THAT IS ALMOST A GUARANTEED SMOKING GUN THAT THE PRICE HAD BEEN ARTIFICIALLY MANIPULATED**\\r\\n__________________\\r\\n\\r\\nEDIT 4:\\r\\n\\r\\nAsk yourself why the market dipped yesterday despite fantastic earnings reports coming out\\r\\n\\r\\nAnswer: Funds were liquidating their other stock market positions to be able to close our their shorts with this market attack today\\r\\n\\r\\nWhy did the markets rally today during the GME crash?\\r\\n\\r\\nBecause the funds re-bought into their old positions in various companies now that they've closed their shorts and no longer at risk of bankruptcy and have additional capital available\\r\\n\\r\\n---------------------------------------\\r\\n\\r\\n**EDIT 5**\\r\\n\\r\\n**For the retards accusing me of being a fake account** somehow shilling for somebody and \"never posted to WSB\" do your fucking DD and don't be sheep believing random hedge fund shills in the comments, **here's my wsb post from 3 years ago, I've been a lurker for even longer**\\r\\n\\r\\nhttps://old.reddit.com/r/wallstreetbets/comments/7cn77y/everyone_at_wsb_waiting_for_jd_earnings/\\r\\n_________________________________________________\\r\\n\\r\\n**Disclaimer: Not investment advice, this is a joke post I'm not making any accusations this is all a parody etc. etc.**\\r\\n\\r\\nDisclaimer: **I'm still long GME** 💎🙌🏻 🚀🚀🚀    1\n",
       "https://www.marketwatch.com/story/microsoft-raises-dividend-by-about-10-2020-09-15?siteid=yhoof2&yptr=yahoo\\r\\n\\r\\nMicrosoft Corp. MSFT, +1.64% announced it will raise its dividend about 10% Tuesday, to 56 cents a share from 51 cents a share. \\r\\n\\r\\nShares have returned 33.4% so far in 2020, while the S&P 500 index SPX, +0.52% has returned 6.2%.\\r\\n\\r\\nThanks for the awards.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
       "Name: body, Length: 2068, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at body value counts\n",
    "body = reddit_df.body.value_counts()\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPVOTE so everyone sees we got SUPPORT</td>\n",
       "      <td>265029</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/sgoqy8nyt2e61.png</td>\n",
       "      <td>11825</td>\n",
       "      <td>2021-01-29 00:40:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GME YOLO update — Jan 28 2021</td>\n",
       "      <td>230844</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/opzucppb15e61.png</td>\n",
       "      <td>23532</td>\n",
       "      <td>2021-01-29 08:06:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...</td>\n",
       "      <td>204920</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>18318</td>\n",
       "      <td>2021-01-29 00:49:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GME YOLO update — Jan 27 2021 ----------------...</td>\n",
       "      <td>185949</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/a309gkm5yxd61.png</td>\n",
       "      <td>15495</td>\n",
       "      <td>2021-01-28 08:15:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can we all take a moment and appreciate the Mo...</td>\n",
       "      <td>184517</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>7105</td>\n",
       "      <td>2021-01-28 11:57:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   score       subreddit  \\\n",
       "0             UPVOTE so everyone sees we got SUPPORT  265029  wallstreetbets   \n",
       "1                      GME YOLO update — Jan 28 2021  230844  wallstreetbets   \n",
       "2  CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...  204920  wallstreetbets   \n",
       "3  GME YOLO update — Jan 27 2021 ----------------...  185949  wallstreetbets   \n",
       "4  Can we all take a moment and appreciate the Mo...  184517  wallstreetbets   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0                https://i.redd.it/sgoqy8nyt2e61.png         11825   \n",
       "1                https://i.redd.it/opzucppb15e61.png         23532   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         18318   \n",
       "3                https://i.redd.it/a309gkm5yxd61.png         15495   \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...          7105   \n",
       "\n",
       "                  date  \n",
       "0  2021-01-29 00:40:34  \n",
       "1  2021-01-29 08:06:23  \n",
       "2  2021-01-29 00:49:11  \n",
       "3  2021-01-28 08:15:35  \n",
       "4  2021-01-28 11:57:32  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the 'body' column.\n",
    "reddit_df.drop(['body'], axis=1, inplace=True)\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPVOTE so everyone sees we got SUPPORT</td>\n",
       "      <td>265029</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/sgoqy8nyt2e61.png</td>\n",
       "      <td>11825</td>\n",
       "      <td>2021-01-29 00:40:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GME YOLO update — Jan 28 2021</td>\n",
       "      <td>230844</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/opzucppb15e61.png</td>\n",
       "      <td>23532</td>\n",
       "      <td>2021-01-29 08:06:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...</td>\n",
       "      <td>204920</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>18318</td>\n",
       "      <td>2021-01-29 00:49:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GME YOLO update — Jan 27 2021 ----------------...</td>\n",
       "      <td>185949</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/a309gkm5yxd61.png</td>\n",
       "      <td>15495</td>\n",
       "      <td>2021-01-28 08:15:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can we all take a moment and appreciate the Mo...</td>\n",
       "      <td>184517</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>7105</td>\n",
       "      <td>2021-01-28 11:57:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>DID WE MISS THE BOTTOM?! How are people this i...</td>\n",
       "      <td>348</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/g1m6u...</td>\n",
       "      <td>283</td>\n",
       "      <td>2020-04-15 17:03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>Favorite Solar Stock(s)?</td>\n",
       "      <td>348</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/jmct3...</td>\n",
       "      <td>176</td>\n",
       "      <td>2020-11-02 10:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>\"NIO forms battery asset company\"</td>\n",
       "      <td>352</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/id8z3...</td>\n",
       "      <td>102</td>\n",
       "      <td>2020-08-20 23:02:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>Amazon is building a $1.5 billion hub for its ...</td>\n",
       "      <td>349</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/5rghg...</td>\n",
       "      <td>145</td>\n",
       "      <td>2017-02-02 03:35:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>Weed legalized in Canada!</td>\n",
       "      <td>356</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/8skaf...</td>\n",
       "      <td>138</td>\n",
       "      <td>2018-06-21 04:38:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2925 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   score  \\\n",
       "0                UPVOTE so everyone sees we got SUPPORT  265029   \n",
       "1                         GME YOLO update — Jan 28 2021  230844   \n",
       "2     CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...  204920   \n",
       "3     GME YOLO update — Jan 27 2021 ----------------...  185949   \n",
       "4     Can we all take a moment and appreciate the Mo...  184517   \n",
       "...                                                 ...     ...   \n",
       "2920  DID WE MISS THE BOTTOM?! How are people this i...     348   \n",
       "2921                           Favorite Solar Stock(s)?     348   \n",
       "2922                  \"NIO forms battery asset company\"     352   \n",
       "2923  Amazon is building a $1.5 billion hub for its ...     349   \n",
       "2924                          Weed legalized in Canada!     356   \n",
       "\n",
       "           subreddit                                                url  \\\n",
       "0     wallstreetbets                https://i.redd.it/sgoqy8nyt2e61.png   \n",
       "1     wallstreetbets                https://i.redd.it/opzucppb15e61.png   \n",
       "2     wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
       "3     wallstreetbets                https://i.redd.it/a309gkm5yxd61.png   \n",
       "4     wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
       "...              ...                                                ...   \n",
       "2920          stocks  https://www.reddit.com/r/stocks/comments/g1m6u...   \n",
       "2921          stocks  https://www.reddit.com/r/stocks/comments/jmct3...   \n",
       "2922          stocks  https://www.reddit.com/r/stocks/comments/id8z3...   \n",
       "2923          stocks  https://www.reddit.com/r/stocks/comments/5rghg...   \n",
       "2924          stocks  https://www.reddit.com/r/stocks/comments/8skaf...   \n",
       "\n",
       "      num_comments                 date  \n",
       "0            11825  2021-01-29 00:40:34  \n",
       "1            23532  2021-01-29 08:06:23  \n",
       "2            18318  2021-01-29 00:49:11  \n",
       "3            15495  2021-01-28 08:15:35  \n",
       "4             7105  2021-01-28 11:57:32  \n",
       "...            ...                  ...  \n",
       "2920           283  2020-04-15 17:03:23  \n",
       "2921           176  2020-11-02 10:46:49  \n",
       "2922           102  2020-08-20 23:02:48  \n",
       "2923           145  2017-02-02 03:35:04  \n",
       "2924           138  2018-06-21 04:38:32  \n",
       "\n",
       "[2925 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows that have at least 1 null value.\n",
    "reddit_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPVOTE so everyone sees we got SUPPORT-- {'neg': 0.0, 'neu': 0.636, 'pos': 0.364, 'compound': 0.5319}\n"
     ]
    }
   ],
   "source": [
    "# Checking Sentiment Scores\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyzer.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(score)))\n",
    "    \n",
    "sentiment_analyzer_scores('UPVOTE so everyone sees we got SUPPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPVOTE so everyone sees we got SUPPORT</td>\n",
       "      <td>265029</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/sgoqy8nyt2e61.png</td>\n",
       "      <td>11825</td>\n",
       "      <td>2021-01-29 00:40:34</td>\n",
       "      <td>0.5319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GME YOLO update — Jan 28 2021</td>\n",
       "      <td>230844</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/opzucppb15e61.png</td>\n",
       "      <td>23532</td>\n",
       "      <td>2021-01-29 08:06:23</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...</td>\n",
       "      <td>204920</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>18318</td>\n",
       "      <td>2021-01-29 00:49:11</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GME YOLO update — Jan 27 2021 ----------------...</td>\n",
       "      <td>185949</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/a309gkm5yxd61.png</td>\n",
       "      <td>15495</td>\n",
       "      <td>2021-01-28 08:15:35</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can we all take a moment and appreciate the Mo...</td>\n",
       "      <td>184517</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>7105</td>\n",
       "      <td>2021-01-28 11:57:32</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   score       subreddit  \\\n",
       "0             UPVOTE so everyone sees we got SUPPORT  265029  wallstreetbets   \n",
       "1                      GME YOLO update — Jan 28 2021  230844  wallstreetbets   \n",
       "2  CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...  204920  wallstreetbets   \n",
       "3  GME YOLO update — Jan 27 2021 ----------------...  185949  wallstreetbets   \n",
       "4  Can we all take a moment and appreciate the Mo...  184517  wallstreetbets   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0                https://i.redd.it/sgoqy8nyt2e61.png         11825   \n",
       "1                https://i.redd.it/opzucppb15e61.png         23532   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         18318   \n",
       "3                https://i.redd.it/a309gkm5yxd61.png         15495   \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...          7105   \n",
       "\n",
       "                  date  compound    neg    neu    pos  \n",
       "0  2021-01-29 00:40:34    0.5319  0.000  0.636  0.364  \n",
       "1  2021-01-29 08:06:23    0.4278  0.000  0.679  0.321  \n",
       "2  2021-01-29 00:49:11   -0.5994  0.107  0.893  0.000  \n",
       "3  2021-01-28 08:15:35    0.4278  0.000  0.841  0.159  \n",
       "4  2021-01-28 11:57:32    0.6369  0.000  0.794  0.206  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add VADER metrics to dataframe\n",
    "reddit_df['compound'] = [analyzer.polarity_scores(v)['compound'] for v in reddit_df['title']]\n",
    "\n",
    "reddit_df['neg'] = [analyzer.polarity_scores(v)['neg'] for v in reddit_df['title']]\n",
    "\n",
    "reddit_df['neu'] = [analyzer.polarity_scores(v)['neu'] for v in reddit_df['title']]\n",
    "\n",
    "reddit_df['pos'] = [analyzer.polarity_scores(v)['pos'] for v in reddit_df['title']]\n",
    "\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_groups = reddit_df.groupby(\"subreddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>investing</th>\n",
       "      <td>1779.078014</td>\n",
       "      <td>424.946302</td>\n",
       "      <td>-0.009373</td>\n",
       "      <td>0.080139</td>\n",
       "      <td>0.842621</td>\n",
       "      <td>0.077234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stocks</th>\n",
       "      <td>1405.035533</td>\n",
       "      <td>311.643655</td>\n",
       "      <td>0.038948</td>\n",
       "      <td>0.060024</td>\n",
       "      <td>0.852797</td>\n",
       "      <td>0.087179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wallstreetbets</th>\n",
       "      <td>29348.439664</td>\n",
       "      <td>2753.270724</td>\n",
       "      <td>0.046143</td>\n",
       "      <td>0.066779</td>\n",
       "      <td>0.834423</td>\n",
       "      <td>0.098805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       score  num_comments  compound       neg       neu  \\\n",
       "subreddit                                                                  \n",
       "investing        1779.078014    424.946302 -0.009373  0.080139  0.842621   \n",
       "stocks           1405.035533    311.643655  0.038948  0.060024  0.852797   \n",
       "wallstreetbets  29348.439664   2753.270724  0.046143  0.066779  0.834423   \n",
       "\n",
       "                     pos  \n",
       "subreddit                 \n",
       "investing       0.077234  \n",
       "stocks          0.087179  \n",
       "wallstreetbets  0.098805  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping Vader Scores for each Subreddit\n",
    "reddit_groups.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>does anyone here have friends and family still...</td>\n",
       "      <td>898</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/ef...</td>\n",
       "      <td>609</td>\n",
       "      <td>2019-12-26 05:47:26</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>Jobs growth soars in November as payrolls surg...</td>\n",
       "      <td>905</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/e6...</td>\n",
       "      <td>496</td>\n",
       "      <td>2019-12-07 00:41:05</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>Yale economists argue that \"the most financial...</td>\n",
       "      <td>894</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/en...</td>\n",
       "      <td>400</td>\n",
       "      <td>2020-01-13 05:35:24</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>Amazon earnings beat: $6.04 per share, vs. $5....</td>\n",
       "      <td>897</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/al...</td>\n",
       "      <td>152</td>\n",
       "      <td>2019-02-01 08:04:51</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>U.S. stocks plunge after report that former na...</td>\n",
       "      <td>890</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/7g...</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-12-02 03:34:52</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  score  subreddit  \\\n",
       "1935  does anyone here have friends and family still...    898  investing   \n",
       "1936  Jobs growth soars in November as payrolls surg...    905  investing   \n",
       "1937  Yale economists argue that \"the most financial...    894  investing   \n",
       "1938  Amazon earnings beat: $6.04 per share, vs. $5....    897  investing   \n",
       "1939  U.S. stocks plunge after report that former na...    890  investing   \n",
       "\n",
       "                                                    url  num_comments  \\\n",
       "1935  https://www.reddit.com/r/investing/comments/ef...           609   \n",
       "1936  https://www.reddit.com/r/investing/comments/e6...           496   \n",
       "1937  https://www.reddit.com/r/investing/comments/en...           400   \n",
       "1938  https://www.reddit.com/r/investing/comments/al...           152   \n",
       "1939  https://www.reddit.com/r/investing/comments/7g...           377   \n",
       "\n",
       "                     date  compound    neg    neu    pos  \n",
       "1935  2019-12-26 05:47:26   -0.0258  0.143  0.717  0.139  \n",
       "1936  2019-12-07 00:41:05    0.3818  0.000  0.776  0.224  \n",
       "1937  2020-01-13 05:35:24    0.0460  0.100  0.792  0.108  \n",
       "1938  2019-02-01 08:04:51    0.4404  0.000  0.642  0.358  \n",
       "1939  2017-12-02 03:34:52    0.3400  0.000  0.893  0.107  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df = reddit_df[reddit_df[\"subreddit\"]!=\"stocks\"]\n",
    "reddit_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aboon\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Changing Subreddit values to be 1 if from WSB and 0 if not.\n",
    "reddit_df['subreddit'] = reddit_df['subreddit'].apply(lambda x:1 if x == \"wallstreetbets\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPVOTE so everyone sees we got SUPPORT</td>\n",
       "      <td>265029</td>\n",
       "      <td>1</td>\n",
       "      <td>https://i.redd.it/sgoqy8nyt2e61.png</td>\n",
       "      <td>11825</td>\n",
       "      <td>2021-01-29 00:40:34</td>\n",
       "      <td>0.5319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GME YOLO update — Jan 28 2021</td>\n",
       "      <td>230844</td>\n",
       "      <td>1</td>\n",
       "      <td>https://i.redd.it/opzucppb15e61.png</td>\n",
       "      <td>23532</td>\n",
       "      <td>2021-01-29 08:06:23</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...</td>\n",
       "      <td>204920</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>18318</td>\n",
       "      <td>2021-01-29 00:49:11</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GME YOLO update — Jan 27 2021 ----------------...</td>\n",
       "      <td>185949</td>\n",
       "      <td>1</td>\n",
       "      <td>https://i.redd.it/a309gkm5yxd61.png</td>\n",
       "      <td>15495</td>\n",
       "      <td>2021-01-28 08:15:35</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can we all take a moment and appreciate the Mo...</td>\n",
       "      <td>184517</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>7105</td>\n",
       "      <td>2021-01-28 11:57:32</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   score  subreddit  \\\n",
       "0             UPVOTE so everyone sees we got SUPPORT  265029          1   \n",
       "1                      GME YOLO update — Jan 28 2021  230844          1   \n",
       "2  CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...  204920          1   \n",
       "3  GME YOLO update — Jan 27 2021 ----------------...  185949          1   \n",
       "4  Can we all take a moment and appreciate the Mo...  184517          1   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0                https://i.redd.it/sgoqy8nyt2e61.png         11825   \n",
       "1                https://i.redd.it/opzucppb15e61.png         23532   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         18318   \n",
       "3                https://i.redd.it/a309gkm5yxd61.png         15495   \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...          7105   \n",
       "\n",
       "                  date  compound    neg    neu    pos  \n",
       "0  2021-01-29 00:40:34    0.5319  0.000  0.636  0.364  \n",
       "1  2021-01-29 08:06:23    0.4278  0.000  0.679  0.321  \n",
       "2  2021-01-29 00:49:11   -0.5994  0.107  0.893  0.000  \n",
       "3  2021-01-28 08:15:35    0.4278  0.000  0.841  0.159  \n",
       "4  2021-01-28 11:57:32    0.6369  0.000  0.794  0.206  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>does anyone here have friends and family still...</td>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/ef...</td>\n",
       "      <td>609</td>\n",
       "      <td>2019-12-26 05:47:26</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>Jobs growth soars in November as payrolls surg...</td>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/e6...</td>\n",
       "      <td>496</td>\n",
       "      <td>2019-12-07 00:41:05</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>Yale economists argue that \"the most financial...</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/en...</td>\n",
       "      <td>400</td>\n",
       "      <td>2020-01-13 05:35:24</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>Amazon earnings beat: $6.04 per share, vs. $5....</td>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/al...</td>\n",
       "      <td>152</td>\n",
       "      <td>2019-02-01 08:04:51</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>U.S. stocks plunge after report that former na...</td>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/7g...</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-12-02 03:34:52</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  score  subreddit  \\\n",
       "1935  does anyone here have friends and family still...    898          0   \n",
       "1936  Jobs growth soars in November as payrolls surg...    905          0   \n",
       "1937  Yale economists argue that \"the most financial...    894          0   \n",
       "1938  Amazon earnings beat: $6.04 per share, vs. $5....    897          0   \n",
       "1939  U.S. stocks plunge after report that former na...    890          0   \n",
       "\n",
       "                                                    url  num_comments  \\\n",
       "1935  https://www.reddit.com/r/investing/comments/ef...           609   \n",
       "1936  https://www.reddit.com/r/investing/comments/e6...           496   \n",
       "1937  https://www.reddit.com/r/investing/comments/en...           400   \n",
       "1938  https://www.reddit.com/r/investing/comments/al...           152   \n",
       "1939  https://www.reddit.com/r/investing/comments/7g...           377   \n",
       "\n",
       "                     date  compound    neg    neu    pos  \n",
       "1935  2019-12-26 05:47:26   -0.0258  0.143  0.717  0.139  \n",
       "1936  2019-12-07 00:41:05    0.3818  0.000  0.776  0.224  \n",
       "1937  2020-01-13 05:35:24    0.0460  0.100  0.792  0.108  \n",
       "1938  2019-02-01 08:04:51    0.4404  0.000  0.642  0.358  \n",
       "1939  2017-12-02 03:34:52    0.3400  0.000  0.893  0.107  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and Y sets\n",
    "y = reddit_df[\"subreddit\"]\n",
    "X = reddit_df.drop(columns=[\"subreddit\",\"title\",\"url\",\"date\",\"num_comments\",\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Breaking sets into train and test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    987\n",
       "1    953\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prediction  Actual\n",
      "0             0       0\n",
      "1             0       0\n",
      "2             0       1\n",
      "3             1       1\n",
      "4             0       0\n",
      "..          ...     ...\n",
      "480           0       0\n",
      "481           0       1\n",
      "482           0       0\n",
      "483           0       0\n",
      "484           1       1\n",
      "\n",
      "[485 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5092783505154639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Attempt #1 - Add Additional Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 80)                400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 3,471\n",
      "Trainable params: 3,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "number_input_features = X_train.shape[1]\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "#third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# check structure of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6982 - accuracy: 0.4393\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6868 - accuracy: 0.5515\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 841us/step - loss: 0.6802 - accuracy: 0.5749\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 878us/step - loss: 0.6711 - accuracy: 0.6399\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 843us/step - loss: 0.6623 - accuracy: 0.6285\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 843us/step - loss: 0.6450 - accuracy: 0.6576\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 863us/step - loss: 0.6594 - accuracy: 0.6334\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6528 - accuracy: 0.6236\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6475 - accuracy: 0.6329\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6621 - accuracy: 0.6207\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 878us/step - loss: 0.6532 - accuracy: 0.6234\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6441 - accuracy: 0.6386\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6423 - accuracy: 0.6307\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 930us/step - loss: 0.6495 - accuracy: 0.6417\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6396 - accuracy: 0.6528\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6283 - accuracy: 0.6608\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6356 - accuracy: 0.6571\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.6499\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6111\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.6543\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6263 - accuracy: 0.6618\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6564\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6541\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6228 - accuracy: 0.6715\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6310 - accuracy: 0.6548\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 754us/step - loss: 0.6408 - accuracy: 0.6287\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6432 - accuracy: 0.6352\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6254 - accuracy: 0.6547\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6434\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6363 - accuracy: 0.6478\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6450 - accuracy: 0.6318\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 822us/step - loss: 0.6314 - accuracy: 0.6528\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6274 - accuracy: 0.6602\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 776us/step - loss: 0.6257 - accuracy: 0.6581\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6355 - accuracy: 0.6490\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6292 - accuracy: 0.6609\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6613\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6206 - accuracy: 0.6546\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6294 - accuracy: 0.6546\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6238 - accuracy: 0.6562\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 776us/step - loss: 0.6165 - accuracy: 0.6616\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 776us/step - loss: 0.6212 - accuracy: 0.6538\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6245 - accuracy: 0.6603\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6225 - accuracy: 0.6567\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6183 - accuracy: 0.6615\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.6453\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6264 - accuracy: 0.6609\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.6598\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.6563\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6185 - accuracy: 0.6617\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6287 - accuracy: 0.6751\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.6352\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.6552\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6444\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6322 - accuracy: 0.6436\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6210 - accuracy: 0.6708\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6177 - accuracy: 0.6719\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6060 - accuracy: 0.6772\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.6697\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.6619\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6402 - accuracy: 0.6360\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6260 - accuracy: 0.6484\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6207 - accuracy: 0.6644\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 954us/step - loss: 0.6321 - accuracy: 0.6525\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6085 - accuracy: 0.6729\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.6516\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6353 - accuracy: 0.6326\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6518\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6164 - accuracy: 0.6686\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6090 - accuracy: 0.6738\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 865us/step - loss: 0.6207 - accuracy: 0.6678\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6383 - accuracy: 0.6427\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6086 - accuracy: 0.6712\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6326 - accuracy: 0.6458\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6184 - accuracy: 0.6558\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6182 - accuracy: 0.6604\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6321 - accuracy: 0.6263\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6222 - accuracy: 0.6578\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6282 - accuracy: 0.6533\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6312 - accuracy: 0.6463\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 975us/step - loss: 0.6165 - accuracy: 0.6654\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.6703\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6289 - accuracy: 0.6448\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 878us/step - loss: 0.6272 - accuracy: 0.6553\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6385 - accuracy: 0.6456\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 932us/step - loss: 0.6124 - accuracy: 0.6687\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 930us/step - loss: 0.6136 - accuracy: 0.6650\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6121 - accuracy: 0.6692\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6273 - accuracy: 0.6525\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6044 - accuracy: 0.6810\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6092 - accuracy: 0.6771\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 954us/step - loss: 0.6141 - accuracy: 0.6525\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 935us/step - loss: 0.6042 - accuracy: 0.6877\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6246 - accuracy: 0.6465\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6157 - accuracy: 0.6685\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6240 - accuracy: 0.6636\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6023 - accuracy: 0.6772\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6192 - accuracy: 0.6526\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6054 - accuracy: 0.6749\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6150 - accuracy: 0.6542\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 0s - loss: 0.6389 - accuracy: 0.6351\n",
      "Loss: 0.6389114856719971, Accuracy: 0.6350515484809875\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Attempt #2: Adding Neurons in Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 90)                450       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                2730      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 3,211\n",
      "Trainable params: 3,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "number_input_features = X_train.shape[1]\n",
    "hidden_nodes_layer1 = 90\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# check structure of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6903 - accuracy: 0.5480\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6826 - accuracy: 0.5733\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6764 - accuracy: 0.6211\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 865us/step - loss: 0.6749 - accuracy: 0.6129\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6658 - accuracy: 0.6075\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6680 - accuracy: 0.6042\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6596 - accuracy: 0.6356\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 944us/step - loss: 0.6546 - accuracy: 0.6476\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6560 - accuracy: 0.6417\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6454 - accuracy: 0.6575\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6500 - accuracy: 0.6394\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6481 - accuracy: 0.6296\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 908us/step - loss: 0.6482 - accuracy: 0.6341\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 910us/step - loss: 0.6447 - accuracy: 0.6368\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 884us/step - loss: 0.6373 - accuracy: 0.6610\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6473 - accuracy: 0.6290\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6488 - accuracy: 0.6377\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6546 - accuracy: 0.6288\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.6376\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6527\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6420 - accuracy: 0.6546\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6330 - accuracy: 0.6525\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6461 - accuracy: 0.6515\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.6514\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6371 - accuracy: 0.6514\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6260 - accuracy: 0.6662\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6361 - accuracy: 0.6414\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6318 - accuracy: 0.6512\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6260 - accuracy: 0.6657\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6397 - accuracy: 0.6519\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6571\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6302 - accuracy: 0.6417\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6415 - accuracy: 0.6268\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6202 - accuracy: 0.6681\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6316 - accuracy: 0.6343\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6376 - accuracy: 0.6538\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6212 - accuracy: 0.6598\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6318 - accuracy: 0.6578\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 857us/step - loss: 0.6347 - accuracy: 0.6527\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6260 - accuracy: 0.6672\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6352 - accuracy: 0.6511\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6583\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6610\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6394 - accuracy: 0.6422\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.6336 - accuracy: 0.6473\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6376 - accuracy: 0.6475\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6333 - accuracy: 0.6540\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6329 - accuracy: 0.6583\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 798us/step - loss: 0.6257 - accuracy: 0.6548\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6257 - accuracy: 0.6625\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6401 - accuracy: 0.6458\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6302 - accuracy: 0.6482\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6148 - accuracy: 0.6669\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6304 - accuracy: 0.6542\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6318 - accuracy: 0.6492\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6239 - accuracy: 0.6655\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6208 - accuracy: 0.6646\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6256 - accuracy: 0.6616\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.6571\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6470 - accuracy: 0.6346\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.6519\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6244 - accuracy: 0.6560\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6298 - accuracy: 0.6601\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6323 - accuracy: 0.6524\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6253 - accuracy: 0.6641\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6134 - accuracy: 0.6749\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6199 - accuracy: 0.6734\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6329\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.6591\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6363\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6465\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.6634\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6723\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6594\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6515\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6227 - accuracy: 0.6531\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6241 - accuracy: 0.6537\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6217 - accuracy: 0.6584\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6223 - accuracy: 0.6710\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.6480\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6105 - accuracy: 0.6814\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.6422\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6140 - accuracy: 0.6631\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6109 - accuracy: 0.6730\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6179 - accuracy: 0.6751\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6237 - accuracy: 0.6627\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6322 - accuracy: 0.6664\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6207 - accuracy: 0.6565\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 798us/step - loss: 0.6161 - accuracy: 0.6714\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6227 - accuracy: 0.6667\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6180 - accuracy: 0.6618\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6318 - accuracy: 0.6409\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6277 - accuracy: 0.6555\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6266 - accuracy: 0.6650\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6257 - accuracy: 0.6555\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6160 - accuracy: 0.6655\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 798us/step - loss: 0.6263 - accuracy: 0.6626\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6306 - accuracy: 0.6646\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 900us/step - loss: 0.6262 - accuracy: 0.6598\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6179 - accuracy: 0.6662\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 0s - loss: 0.6476 - accuracy: 0.6082\n",
      "Loss: 0.6476240754127502, Accuracy: 0.6082473993301392\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optmization Attempt #3 - Add Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 80)                400       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 2,861\n",
      "Trainable params: 2,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "number_input_features = X_train.shape[1]\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# check structure of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6900 - accuracy: 0.5350\n",
      "Epoch 2/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6873 - accuracy: 0.5783\n",
      "Epoch 3/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6814 - accuracy: 0.5238\n",
      "Epoch 4/150\n",
      "46/46 [==============================] - 0s 814us/step - loss: 0.6765 - accuracy: 0.5987\n",
      "Epoch 5/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6740 - accuracy: 0.5883\n",
      "Epoch 6/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6706 - accuracy: 0.6188\n",
      "Epoch 7/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6594 - accuracy: 0.6187\n",
      "Epoch 8/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6547 - accuracy: 0.6431\n",
      "Epoch 9/150\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6529 - accuracy: 0.6398\n",
      "Epoch 10/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6581 - accuracy: 0.6004\n",
      "Epoch 11/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6521 - accuracy: 0.6285\n",
      "Epoch 12/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.6654\n",
      "Epoch 13/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.6528\n",
      "Epoch 14/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6300\n",
      "Epoch 15/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6538 - accuracy: 0.6397\n",
      "Epoch 16/150\n",
      "46/46 [==============================] - 0s 930us/step - loss: 0.6367 - accuracy: 0.6499\n",
      "Epoch 17/150\n",
      "46/46 [==============================] - 0s 998us/step - loss: 0.6388 - accuracy: 0.6400\n",
      "Epoch 18/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6416 - accuracy: 0.6385\n",
      "Epoch 19/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6375\n",
      "Epoch 20/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6380 - accuracy: 0.6497\n",
      "Epoch 21/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6603\n",
      "Epoch 22/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.6462\n",
      "Epoch 23/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.6440\n",
      "Epoch 24/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6464\n",
      "Epoch 25/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6347 - accuracy: 0.6425\n",
      "Epoch 26/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6356 - accuracy: 0.6597\n",
      "Epoch 27/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.6604\n",
      "Epoch 28/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6402 - accuracy: 0.6546\n",
      "Epoch 29/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6242 - accuracy: 0.6609\n",
      "Epoch 30/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6257 - accuracy: 0.6554\n",
      "Epoch 31/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6470\n",
      "Epoch 32/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6311 - accuracy: 0.6512\n",
      "Epoch 33/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6590\n",
      "Epoch 34/150\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6364 - accuracy: 0.6400\n",
      "Epoch 35/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6345 - accuracy: 0.6540\n",
      "Epoch 36/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6317 - accuracy: 0.6565\n",
      "Epoch 37/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6353\n",
      "Epoch 38/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6276 - accuracy: 0.6696\n",
      "Epoch 39/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6342 - accuracy: 0.6519\n",
      "Epoch 40/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.6394\n",
      "Epoch 41/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6264 - accuracy: 0.6630\n",
      "Epoch 42/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6337 - accuracy: 0.6525\n",
      "Epoch 43/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6384 - accuracy: 0.6464\n",
      "Epoch 44/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.6337\n",
      "Epoch 45/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6455\n",
      "Epoch 46/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6358\n",
      "Epoch 47/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.6527\n",
      "Epoch 48/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.6551\n",
      "Epoch 49/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6533\n",
      "Epoch 50/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.6600\n",
      "Epoch 51/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.6425\n",
      "Epoch 52/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6450 - accuracy: 0.6352\n",
      "Epoch 53/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.6540\n",
      "Epoch 54/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6438\n",
      "Epoch 55/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6458 - accuracy: 0.6430\n",
      "Epoch 56/150\n",
      "46/46 [==============================] - 0s 853us/step - loss: 0.6340 - accuracy: 0.6617\n",
      "Epoch 57/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6209 - accuracy: 0.6716\n",
      "Epoch 58/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6238 - accuracy: 0.6712\n",
      "Epoch 59/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6371 - accuracy: 0.6444\n",
      "Epoch 60/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6395 - accuracy: 0.6336\n",
      "Epoch 61/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6328 - accuracy: 0.6667\n",
      "Epoch 62/150\n",
      "46/46 [==============================] - 0s 854us/step - loss: 0.6305 - accuracy: 0.6608\n",
      "Epoch 63/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6294 - accuracy: 0.6507\n",
      "Epoch 64/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6224 - accuracy: 0.6629\n",
      "Epoch 65/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6316 - accuracy: 0.6368\n",
      "Epoch 66/150\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.6355 - accuracy: 0.6468\n",
      "Epoch 67/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.6512\n",
      "Epoch 68/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.6406\n",
      "Epoch 69/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6333 - accuracy: 0.6542\n",
      "Epoch 70/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6319 - accuracy: 0.6471\n",
      "Epoch 71/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6321 - accuracy: 0.6473\n",
      "Epoch 72/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6257 - accuracy: 0.6650\n",
      "Epoch 73/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6185 - accuracy: 0.6595\n",
      "Epoch 74/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6404 - accuracy: 0.6385\n",
      "Epoch 75/150\n",
      "46/46 [==============================] - 0s 954us/step - loss: 0.6155 - accuracy: 0.6597\n",
      "Epoch 76/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6325 - accuracy: 0.6384\n",
      "Epoch 77/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6275 - accuracy: 0.6650\n",
      "Epoch 78/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6284 - accuracy: 0.6552\n",
      "Epoch 79/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6223 - accuracy: 0.6714\n",
      "Epoch 80/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6310 - accuracy: 0.6617\n",
      "Epoch 81/150\n",
      "46/46 [==============================] - 0s 932us/step - loss: 0.6267 - accuracy: 0.6520\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 931us/step - loss: 0.6269 - accuracy: 0.6600\n",
      "Epoch 83/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.6583\n",
      "Epoch 84/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6184 - accuracy: 0.6632\n",
      "Epoch 85/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6196 - accuracy: 0.6679\n",
      "Epoch 86/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6093 - accuracy: 0.6737\n",
      "Epoch 87/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6296 - accuracy: 0.6482\n",
      "Epoch 88/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6232 - accuracy: 0.6560\n",
      "Epoch 89/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.6505\n",
      "Epoch 90/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6316 - accuracy: 0.6467\n",
      "Epoch 91/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.6704\n",
      "Epoch 92/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6216 - accuracy: 0.6673\n",
      "Epoch 93/150\n",
      "46/46 [==============================] - 0s 833us/step - loss: 0.6366 - accuracy: 0.6506\n",
      "Epoch 94/150\n",
      "46/46 [==============================] - 0s 843us/step - loss: 0.6186 - accuracy: 0.6591\n",
      "Epoch 95/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6153 - accuracy: 0.6700\n",
      "Epoch 96/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6237 - accuracy: 0.6511\n",
      "Epoch 97/150\n",
      "46/46 [==============================] - 0s 843us/step - loss: 0.6085 - accuracy: 0.6771\n",
      "Epoch 98/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6311 - accuracy: 0.6430\n",
      "Epoch 99/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6268 - accuracy: 0.6629\n",
      "Epoch 100/150\n",
      "46/46 [==============================] - 0s 858us/step - loss: 0.6201 - accuracy: 0.6599\n",
      "Epoch 101/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5551 - accuracy: 0.71 - 0s 865us/step - loss: 0.6215 - accuracy: 0.6551\n",
      "Epoch 102/150\n",
      "46/46 [==============================] - 0s 821us/step - loss: 0.6285 - accuracy: 0.6523\n",
      "Epoch 103/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6221 - accuracy: 0.6591\n",
      "Epoch 104/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6209 - accuracy: 0.6529\n",
      "Epoch 105/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6300 - accuracy: 0.6569\n",
      "Epoch 106/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6380 - accuracy: 0.6573\n",
      "Epoch 107/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6255 - accuracy: 0.6464\n",
      "Epoch 108/150\n",
      "46/46 [==============================] - 0s 843us/step - loss: 0.6243 - accuracy: 0.6502\n",
      "Epoch 109/150\n",
      "46/46 [==============================] - 0s 799us/step - loss: 0.6202 - accuracy: 0.6631\n",
      "Epoch 110/150\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6301 - accuracy: 0.6413\n",
      "Epoch 111/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6070 - accuracy: 0.6806\n",
      "Epoch 112/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6209 - accuracy: 0.6633\n",
      "Epoch 113/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6096 - accuracy: 0.6734\n",
      "Epoch 114/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6246 - accuracy: 0.6574\n",
      "Epoch 115/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6261 - accuracy: 0.6573\n",
      "Epoch 116/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6335 - accuracy: 0.6572\n",
      "Epoch 117/150\n",
      "46/46 [==============================] - 0s 908us/step - loss: 0.6299 - accuracy: 0.6569\n",
      "Epoch 118/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6299 - accuracy: 0.6530\n",
      "Epoch 119/150\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6237 - accuracy: 0.6549\n",
      "Epoch 120/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6100 - accuracy: 0.6827\n",
      "Epoch 121/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6222 - accuracy: 0.6598\n",
      "Epoch 122/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6263 - accuracy: 0.6428\n",
      "Epoch 123/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6271 - accuracy: 0.6459\n",
      "Epoch 124/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6126 - accuracy: 0.6709\n",
      "Epoch 125/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6177 - accuracy: 0.6581\n",
      "Epoch 126/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6293 - accuracy: 0.6542\n",
      "Epoch 127/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6241 - accuracy: 0.6480\n",
      "Epoch 128/150\n",
      "46/46 [==============================] - 0s 865us/step - loss: 0.6154 - accuracy: 0.6658\n",
      "Epoch 129/150\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6184 - accuracy: 0.6654\n",
      "Epoch 130/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6303 - accuracy: 0.6497\n",
      "Epoch 131/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6165 - accuracy: 0.6664\n",
      "Epoch 132/150\n",
      "46/46 [==============================] - 0s 901us/step - loss: 0.6172 - accuracy: 0.6587\n",
      "Epoch 133/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6148 - accuracy: 0.6680\n",
      "Epoch 134/150\n",
      "46/46 [==============================] - 0s 965us/step - loss: 0.6230 - accuracy: 0.6611\n",
      "Epoch 135/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6464\n",
      "Epoch 136/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6198 - accuracy: 0.6581\n",
      "Epoch 137/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6185 - accuracy: 0.6561\n",
      "Epoch 138/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6336 - accuracy: 0.6407\n",
      "Epoch 139/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6154 - accuracy: 0.6609\n",
      "Epoch 140/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6341 - accuracy: 0.6456\n",
      "Epoch 141/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6151 - accuracy: 0.6737\n",
      "Epoch 142/150\n",
      "46/46 [==============================] - 0s 821us/step - loss: 0.6278 - accuracy: 0.6454\n",
      "Epoch 143/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6202 - accuracy: 0.6635\n",
      "Epoch 144/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6085 - accuracy: 0.6790\n",
      "Epoch 145/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6173 - accuracy: 0.6569\n",
      "Epoch 146/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6131 - accuracy: 0.6697\n",
      "Epoch 147/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6159 - accuracy: 0.6605\n",
      "Epoch 148/150\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6065 - accuracy: 0.6756\n",
      "Epoch 149/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6287 - accuracy: 0.6477\n",
      "Epoch 150/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6190 - accuracy: 0.6689\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "fit_model = nn.fit(X_train, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 0s - loss: 0.6367 - accuracy: 0.6103\n",
      "Loss: 0.6367443203926086, Accuracy: 0.6103093028068542\n"
     ]
    }
   ],
   "source": [
    "# evaluate model using test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Attempt #4: Change Activation Function w/ Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkpoint path and filenames\n",
    "import os\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 80)                400       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 2,861\n",
      "Trainable params: 2,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "number_input_features = X_train.shape[1]\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='tanh'))\n",
    "\n",
    "# check structure of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 821us/step - loss: 0.6304 - accuracy: 0.6479\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6148 - accuracy: 0.6676\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6205 - accuracy: 0.6792\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6252 - accuracy: 0.6375\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 866us/step - loss: 0.6254 - accuracy: 0.6615\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6180 - accuracy: 0.6528\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6214 - accuracy: 0.6723\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6234 - accuracy: 0.6603\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 776us/step - loss: 0.6108 - accuracy: 0.6680\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6088 - accuracy: 0.6767\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6243 - accuracy: 0.6498\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6187 - accuracy: 0.6468\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6211 - accuracy: 0.6591\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 753us/step - loss: 0.6189 - accuracy: 0.6693\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6100 - accuracy: 0.6768\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 753us/step - loss: 0.6143 - accuracy: 0.6625\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6067 - accuracy: 0.6803\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.6807\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.71 - 0s 1ms/step - loss: 0.6165 - accuracy: 0.6707\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6165 - accuracy: 0.6685\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.6524\n",
      "Epoch 22/100\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6954 - accuracy: 0.6562\n",
      "Epoch 00022: saving model to checkpoints\\weights.22.hdf5\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.6549\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.6495\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.6589\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 976us/step - loss: 0.6104 - accuracy: 0.6548\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6490\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6399\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6804\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6105 - accuracy: 0.6612\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.6757\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6104 - accuracy: 0.6750\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6189 - accuracy: 0.6543\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6219 - accuracy: 0.6641\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.6665\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6172 - accuracy: 0.6753\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6044 - accuracy: 0.6663\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6151 - accuracy: 0.6611\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.6729\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6722\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6191 - accuracy: 0.6581\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6165 - accuracy: 0.6694\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6169 - accuracy: 0.6502\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6271 - accuracy: 0.6522\n",
      "Epoch 44/100\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5992 - accuracy: 0.6562\n",
      "Epoch 00044: saving model to checkpoints\\weights.44.hdf5\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6107 - accuracy: 0.6760\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.6805\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.6551\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5995 - accuracy: 0.6818\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6240 - accuracy: 0.6485\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6024 - accuracy: 0.6746\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6201 - accuracy: 0.6522\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6229 - accuracy: 0.6591\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6276 - accuracy: 0.6553\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6244 - accuracy: 0.6500\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6375\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6266 - accuracy: 0.6437\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6175 - accuracy: 0.6629\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.6620\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 858us/step - loss: 0.6060 - accuracy: 0.6687\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6200 - accuracy: 0.6624\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 976us/step - loss: 0.5966 - accuracy: 0.6775\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6172 - accuracy: 0.6554\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6053 - accuracy: 0.6740\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.5976 - accuracy: 0.6812\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6209 - accuracy: 0.6560\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6150 - accuracy: 0.6593\n",
      "Epoch 66/100\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6025 - accuracy: 0.7812\n",
      "Epoch 00066: saving model to checkpoints\\weights.66.hdf5\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6148 - accuracy: 0.6601\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.6665\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6205 - accuracy: 0.6623\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6082 - accuracy: 0.6728\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6624\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.6500\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6110 - accuracy: 0.6564\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6160 - accuracy: 0.6624\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6087 - accuracy: 0.6732\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6174 - accuracy: 0.6360\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6143 - accuracy: 0.6589\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 931us/step - loss: 0.6146 - accuracy: 0.6521\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6110 - accuracy: 0.6684\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6175 - accuracy: 0.6608\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6179 - accuracy: 0.6504\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6027 - accuracy: 0.6736\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6054 - accuracy: 0.6798\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6131 - accuracy: 0.6697\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 865us/step - loss: 0.6020 - accuracy: 0.6682\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6094 - accuracy: 0.6699\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6203 - accuracy: 0.6659\n",
      "Epoch 87/100\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6292 - accuracy: 0.6250\n",
      "Epoch 00087: saving model to checkpoints\\weights.87.hdf5\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.6530\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6028 - accuracy: 0.6730\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6125 - accuracy: 0.6601\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6263 - accuracy: 0.6316\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6073 - accuracy: 0.6544\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6132 - accuracy: 0.6567\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6093 - accuracy: 0.6618\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6177 - accuracy: 0.6545\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.6675\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6096 - accuracy: 0.6594\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.6496\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.6722\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6027 - accuracy: 0.6816\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 998us/step - loss: 0.6189 - accuracy: 0.6525\n",
      "16/16 - 0s - loss: 0.6669 - accuracy: 0.6165\n",
      "Loss: 0.6669048070907593, Accuracy: 0.6164948344230652\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# create callback that saves weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=1000)\n",
    "\n",
    "# train model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100,callbacks=[cp_callback])\n",
    "\n",
    "# evaluate model using test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
