{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dependencies\n",
    "from path import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#load VADER\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPVOTE so everyone sees we got SUPPORT</td>\n",
       "      <td>265029</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/sgoqy8nyt2e61.png</td>\n",
       "      <td>11825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-29 00:40:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GME YOLO update — Jan 28 2021</td>\n",
       "      <td>230844</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/opzucppb15e61.png</td>\n",
       "      <td>23532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-29 08:06:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...</td>\n",
       "      <td>204920</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>18318</td>\n",
       "      <td>LEAVE ROBINHOOD. They dont deserve to make mon...</td>\n",
       "      <td>2021-01-29 00:49:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GME YOLO update — Jan 27 2021 ----------------...</td>\n",
       "      <td>185949</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/a309gkm5yxd61.png</td>\n",
       "      <td>15495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 08:15:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can we all take a moment and appreciate the Mo...</td>\n",
       "      <td>184517</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>7105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 11:57:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   score       subreddit  \\\n",
       "0             UPVOTE so everyone sees we got SUPPORT  265029  wallstreetbets   \n",
       "1                      GME YOLO update — Jan 28 2021  230844  wallstreetbets   \n",
       "2  CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...  204920  wallstreetbets   \n",
       "3  GME YOLO update — Jan 27 2021 ----------------...  185949  wallstreetbets   \n",
       "4  Can we all take a moment and appreciate the Mo...  184517  wallstreetbets   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0                https://i.redd.it/sgoqy8nyt2e61.png         11825   \n",
       "1                https://i.redd.it/opzucppb15e61.png         23532   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         18318   \n",
       "3                https://i.redd.it/a309gkm5yxd61.png         15495   \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...          7105   \n",
       "\n",
       "                                                body                 date  \n",
       "0                                                NaN  2021-01-29 00:40:34  \n",
       "1                                                NaN  2021-01-29 08:06:23  \n",
       "2  LEAVE ROBINHOOD. They dont deserve to make mon...  2021-01-29 00:49:11  \n",
       "3                                                NaN  2021-01-28 08:15:35  \n",
       "4                                                NaN  2021-01-28 11:57:32  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data\n",
    "data = Path('Resources/reddit.csv')\n",
    "reddit_df = pd.read_csv(data)\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           object\n",
       "score            int64\n",
       "subreddit       object\n",
       "url             object\n",
       "num_comments     int64\n",
       "body            object\n",
       "date            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking DTypes\n",
    "reddit_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "investing         987\n",
       "stocks            985\n",
       "wallstreetbets    953\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at subreddit value counts\n",
    "subreddit = reddit_df.subreddit.value_counts()\n",
    "subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Please use this thread to discuss your portfolio, learn of other stock tickers, and help out users by giving constructive criticism.\\r\\n\\r\\nWhy quarterly?  Public companies report earnings quarterly; many investors take this as an opportunity to rebalance their portfolios.  We highly recommend you do some reading:  A list of [relevant posts & book recommendations.](https://www.reddit.com/r/stocks/wiki/index#wiki_relevant_posts_.26amp.3B_book_recommendations)\\r\\n\\r\\nYou can find stocks on your own by using a scanner like your broker's or [Finviz.](https://finviz.com/screener.ashx)  To help further, here's a list of [relevant websites.](https://www.reddit.com/r/stocks/wiki/index#wiki_relevant_websites.2Fapps)\\r\\n\\r\\nIf you don't have a broker yet, see our [list of brokers](https://www.reddit.com/r/stocks/wiki/index#wiki_brokers_for_investing) or search old posts.  If you haven't started investing or trading yet, then setup your [paper trading.](https://www.reddit.com/r/stocks/wiki/index#wiki_is_there_a_way_to_practice.3F)\\r\\n\\r\\nBe aware of [Business Cycle Investing](https://eresearch.fidelity.com/eresearch/markets_sectors/sectors/si_business_cycle.jhtml?tab=sibusiness) which Fidelity issues updates to the state of global business cycles every 1 to 3 months (note: Fidelity changes their links often, so search for it since their take on it is enlightening).  [Investopedia's take on the Business Cycle](https://www.investopedia.com/articles/investing/061316/business-cycle-investing-ratios-use-each-cycle.asp) and their [video.](https://www.investopedia.com/video/play/business-cycle/)\\r\\n\\r\\nIf you need help with a falling stock price, check out Investopedia's [The Art of Selling A Losing Position](https://www.investopedia.com/articles/02/022002.asp) and their [list of biases.](https://www.investopedia.com/articles/stocks/08/capital-losses.asp)\\r\\n\\r\\nHere's a list of all the [previous portfolio stickies.](https://www.reddit.com/r/stocks/search?q=author%3Aautomoderator+%22Rate+My+Portfolio%22+-+r%2FStocks+Quarterly+Thread&restrict_sr=on&include_over_18=on&sort=new&t=all)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        4\n",
       "[link](https://www.cnbc.com/2020/12/20/mcconnell-says-congress-has-agreed-to-900-billion-coronavirus-stimulus-deal.html?utm_content=Main&utm_medium=Social&utm_source=Facebook&fbclid=IwAR2uRFFTS_C1F32Pn2swO-ha4pde1W0MUJWq8RZywN_54slLZ-vuG98R7no#Echobox=1608504254)\\r\\n\\r\\nKEY POINTS\\r\\nCongress reached a deal Sunday on a $900 billion coronavirus relief package, according to Senate Majority Leader Mitch McConnell.\\r\\nLawmakers will move to vote on the proposal, along with a full-year government spending bill, as soon as Sunday night.\\r\\nMillions of Americans have awaited aid for months as Congress failed to agree on another plan to boost a health-care system and economy buckling under the weight of the pandemic.\\r\\n\\r\\nCongress reached a deal Sunday on a $900 billion coronavirus relief package, a long-delayed effort to boost an American health-care system and economy buckling under the weight of the pandemic.\\r\\n\\r\\nSenate Majority Leader Mitch McConnell, R-Ky., announced the agreement on a pandemic aid and full-year government spending bill. He did not delve into many details. Congressional leaders have not yet released text of the more than $2 trillion legislation, which they hope to pass in the coming hours.\\r\\n\\r\\nThe agreement follows months of sniping on Capitol Hill over how best to fight a once-in-a-century crisis. A new round of aid cannot come soon enough for the millions of Americans who have tried to scrape together enough money to afford food and housing.\\r\\n\\r\\nThe $900 billion coronavirus relief plan under negotiation on Capitol Hill was set to include direct payments of $600 to many adults. Some families were also expected to get $600 per child.\\r\\n\\r\\nThe proposal was set to put at least $300 billion into small business assistance including Paycheck Protection Program loans. It would also add a $300 federal unemployment supplement and temporarily keep in place pandemic-era programs that expanded unemployment insurance eligibility.\\r\\n\\r\\nIf those provisions expire the day after Christmas, 12 million people will lose unemployment benefits.\\r\\n\\r\\nThe measure was also set to put critical funding into the distribution of the two FDA-approved Covid-19 vaccines. Health-care workers and top government officials have started to receive shots, and widespread inoculation in the coming months will help the world to emerge from the pandemic’s shadow.\\r\\n\\r\\nThe rescue package was also set to send relief to hospitals, many of which have struggled to keep up with a flood of Covid-19 patients. It was also expected to put new money into education and transportation.\\r\\n\\r\\nAs lawmakers finally reach a deal, the help comes too late for the nearly 8 million people estimated to have fallen into poverty since June. Many in Congress say the proposal will not go nearly far enough to address the scope of the health and economic crisis.\\r\\n\\r\\nProgressives and some Republicans have pushed for larger direct payments and retroactive federal unemployment payments. A $600 weekly supplement that buoyed millions of jobless Americans in the early months of the pandemic expired over the summer, and it took Congress months to agree to reinstate it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        2\n",
       "We’ve all seen it parroted on every investing related thread in the history of Reddit- “time in the market beats timing the market”. But I feel like this phrase gets misused quite a lot, and I would like to take this boring workday of a Saturday to just show the power of what “time in the market” actually has. \\r\\n\\r\\n1. What “time in the market” means and what it doesn’t mean \\r\\n\\r\\nTime in the market means, basically, maintaining ownership of assets that either 1, typically appreciate in value over time (stocks, real estate, commodities, etc) or 2, that produce a steady, ideally increasing, stream of income (dividend paying stocks, a business, rental properties, debt, etc). By “time in the market” it means that ownership of these assets over long periods of time, as in years and decades, is the key to wealth accumulation. If you look at most wealthy person alive today and in history, they gained their wealth through assets. They accumulate assets and own them. \\r\\n\\r\\n“Time in the market” does NOT mean buying clearly overvalued hype stocks because “I’m in for the long term”. I’m not gonna say any because I don’t want the comments to just be arguing about whether or not tesla is overvalued, but I hope you get the idea. However this doesn’t mean to just let your cash sit on the sidelines “waiting for a crash”. Typically there is no reason to have all your net worth tied up in cash, as it is the only asset class guaranteed to lose value over time. \\r\\n\\r\\nRather, you should be in the middle: continuing to own assets you already own and being on the lookout for more, fairly valued ones. I promise you that you can find value out there if you look for it. Even then you don’t necessarily always have to be buying. Sometimes doing nothing is the best choice. \\r\\n\\r\\n2. You’re probably wasting your time (and money) \\r\\n\\r\\nIf you’re anticipating a crash, good luck. There have been 8 major crashes since the 1920’s: an average of one every 12 years. There have been flash crashes and small recession but these shouldn’t concern you at all. On the large scale, the market has trended up for most of its existence. What makes this time different, exactly? Bulls have a tendency to believe that this time is different, but bears can have the same mindset, especially  considering that the US has been in a bull market for most of its history. So what makes this time different? \\r\\n\\r\\nSure, we will enter a bear market eventually but the US market has never failed retest its highs. If you’re selling because you anticipate a “correction”, you’re just wasting your time and money. Corrections are a blip on the radar over time. They are normal, healthy and should be seen as a good thing, just the market breathing, per se; nobody actually thinks “stocks only go up and never go down”. \\r\\n\\r\\nOnce you gain real money, in the high six figures and up, taxes will really start to eat into you. Selling positions with the intent to buy back in after a correction is probably an unprofitable endeavor. Why pay a good chunk of your earnings in taxes just to buy back 10% cheaper, especially when the 10% drop may or may not happen when you expect it to? This ties in to the last paragraph of point one, sometimes it’s best to do nothing and just continue to hold, letting your money work for you. \\r\\n\\r\\n3. Generational wealth\\r\\n\\r\\nThis is my main point. The Rothschilds, for example, have been building an empire for almost 300 years. That is 300 years of compounding interest. One thing they have done is accumulate assets, not sell them. The wealthy families of the Netherlands have been passing down assets for almost 400 years. \\r\\n\\r\\nEven on a less grandiose scale, just look to this subreddit. You’ll notice a lot of the users with higher portfolio balances probably received a nice inheritance somewhere along the way. This isn’t a bad thing and shouldn’t be shamed. After all, isn’t that everyone’s goal, to pass their wealth into their children? Unfortunately, with inheritances, a huge majority of inherited wealth is lost by the third generation. When the younger generation doesn’t know how to properly manage wealth, they end up wasting it all instead of further building it up. \\r\\n\\r\\n4. Compound interest \\r\\n\\r\\nSome call it the eighth wonder of the world, and rightfully so. There is no reason to interrupt compound interest unnecessarily. I would hope that most people here are investing with the goal of attaining compound interest, and selling your compounding assets is a solid way to halt it. \\r\\n\\r\\n5. Dividends \\r\\n\\r\\nWhether or not you chase dividends, I think we can all agree that we get some form of dividends or income from our investments. Dividends really show their power after several years of ownership. Buffett, for example, gets a 40% annual return from dividends on his initial Coca Cola investment. Fourty percent! And he doesn’t even DRIP them. Why on earth would people get rid of their assets that have potential to give those kind of returns after some years of ownership is beyond me. If you do a dividend return calculator going back multiple decades, you’ll find that most dividend paying securities will have similar returns once you have mature ownership of them. \\r\\n\\r\\n6. On “timing the market”\\r\\n\\r\\nThis is probably a controversial one but I definitely don’t believe in just buying whatever tickers you want because “time in the market beats timing the market”. Like I said above, time in > timing because of generational wealth, compound interest and ownership. It doesn’t mean buying the hottest Reddit ticker because you’re in for the long term. Taking well assessed risks with positive and realistic upside is ideal. \\r\\n\\r\\nSpending time to make sure the investment you’re about to make is a good investment is smart. If spending a week or two assessing your decision is a way to “miss out on sick gains bro, it’ll go up another 50% before you buy”, it’s probably a FOMO stock and you shouldn’t be in in the first place. If patience is key, that means patience with buying is just as important as patience with holding. \\r\\n\\r\\nAt the end of the day I’m a believer in ownership. Looking through most of wealthy individuals of today and in history, they all had one thing in common: they maintained possession of assets. They don’t sell their portfolios because they’re scared of a crash, they don’t have their net worth in a savings account. They assume a little bit of managed risk and let their money work for them. \\r\\n\\r\\nI made this post because I have to work on a Saturday and have nothing going on, I hope you at least enjoyed it or disagree with it so we can have some discussion going.    2\n",
       "YouTube video of Buffett talking about GE's problems:\\r\\n\\r\\nhttps://youtu.be/TM9ztFadLLs?t=4m10s\\r\\n\\r\\nThe Markopolos report is essentially quantifying these problems and showing that they are far more serious than previously believed\\r\\n\\r\\nRead the report here (it's a slide deck, easy to understand):\\r\\n\\r\\nhttp://fm.cnbc.com/applications/cnbc.com/resources/editorialfiles/2019/8/15/2019_08_15_GE_Whistleblower_Report.pdf\\r\\n\\r\\nBe careful, everyone                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     2\n",
       "https://www.cnbc.com/2019/10/01/charles-schwab-is-eliminating-online-commissions-for-trading-in-us-stocks-and-etfs.html\\r\\n\\r\\n\"Charles Scwab said on Tuesday that it is ending commissions for online trading in U.S. stocks, exchange-traded funds and options. The changes will apply to securities on Canadian exchanges as well.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ..\n",
       "https://www.bloomberg.com/news/articles/2018-02-22/snap-royalty-kylie-jenner-erased-a-billion-dollars-in-one-tweet                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
       ">According to the The Shiller price-to-earnings (P/E) ratio is a P/E ratio based on the average inflation-adjusted earnings from the previous 10 years. Over 150 years of history, the Shiller P/E ratio for the S&P 500 has a mean (average) of 16.8 and a median of 15.8. Right now, the Shiller S&P ratio for the S&P 500 is 34.5 -- more than double its historic average. [Source](https://www.fool.com/amp/investing/2021/01/18/the-stock-markets-telltale-crash-signal-is-back/) \\r\\n\\r\\n\\r\\n&nbsp;\\r\\n\\r\\n>When looking back, there have only been five times in history where the S&P 500 has maintained a move above a P/E of 30: \\r\\n\\r\\n\\r\\n&nbsp;\\r\\n\\r\\n**1929:** After the Black Tuesday crash, the iconic Dow Jones Industrial Average (DJINDICES:^DJI) went on to lose approximately 89% of its value.\\r\\n\\r\\n&nbsp;\\r\\n\\r\\n**1997-2000:** Before the dot-com bubble burst, the Shiller P/E ratio for the S&P 500 hit an all-time high of 44.2. Nearly half the value of the S&P 500 was wiped away after the dot-com bubble burst, with the Nasdaq Composite (NASDAQINDEX:^IXIC) hit even harder.\\r\\nQ3 \\r\\n\\r\\n&nbsp;\\r\\n\\r\\n**2018:** Throughout much of the third quarter of 2018, the Shiller P/E ratio sat above 30. This was followed by a fourth quarter swoon that saw the S&P 500 lose as much as 19.8%.\\r\\n\\r\\n&nbsp;\\r\\n\\r\\n**Q4 2019/Q1 2020:** Prior to the coronavirus crash in the first quarter of 2020, the Shiller P/E ratio had, again, crossed above 30. The S&P 500 lost 34% in 33 calendar days during the COVID-19 chaos of February and March.\\r\\n\\r\\n&nbsp;\\r\\n\\r\\n**Q3 2020-Current:** To be determined.\\r\\n\\r\\n&nbsp;\\r\\n\\r\\n\\r\\n>Historically, when the Shiller P/E ratio for the S&P 500 gets above 30, bad things happen.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
       "What are you guys thinking about this move, I personally bought some MJ and CGC                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
       "[https://www.bloomberg.com/news/articles/2019-12-04/warren-is-drafting-u-s-legislation-to-reverse-mega-mergers?srnd=premium](https://www.bloomberg.com/news/articles/2019-12-04/warren-is-drafting-u-s-legislation-to-reverse-mega-mergers?srnd=premium)\\r\\n\\r\\n&#x200B;\\r\\n\\r\\n \\r\\n\\r\\nU.S. Senator Elizabeth Warren is drafting a bill that would call on  regulators to retroactively review about two decades of “mega mergers”  and ban such deals going forward.\\r\\n\\r\\nWarren’s  staff recently circulated a proposal for sweeping anti-monopoly  legislation, which would deliver on a presidential campaign promise to  check the power of Big Tech and other industries. Although the Trump  administration is currently exploring their own antitrust probes, the  proposal is likely to face resistance from lawmakers.\\r\\n\\r\\n \\r\\n\\r\\nAccording to a draft of the bill reviewed by Bloomberg, the proposal  would expand antitrust law beyond the so-called consumer welfare  standard, an approach that has driven antitrust policy since the 1970s.  Under the current framework, the federal government evaluates mergers  primarily based on potential harm to consumers through higher prices or  decreased quality. The new bill would direct the government to also  consider the impact on entrepreneurs, innovation, privacy and workers.\\r\\n\\r\\nWarren’s bill, tentatively titled the Anti-Monopoly and  Competition Restoration Act, would also ban non-compete and no-poaching  agreements for workers and protect the rights of gig economy workers,  such as drivers for [Uber Technologies Inc.](https://www.bloomberg.com/quote/UBER:US), to organize.\\r\\n\\r\\nA draft of Warren’s bill was included in an email Monday from  Spencer Waller, the director of the Institute for Consumer Antitrust  Studies at Loyola University Chicago. Waller urged fellow academics to  sign a petition supporting it. He said Warren was working on the bill  with Representative David Cicilline, the most prominent voice on  antitrust issues in the House. Waller declined to comment on the email.\\r\\n\\r\\nRepresentatives for Cicilline and Warren declined to comment. The existence of the bill and Warren’s support of it were [reported earlier](https://www.theinformation.com/briefings/129fbf) this week by the technology publication the Information.\\r\\n\\r\\nIn  Washington, there is some support across the political spectrum for  increased antitrust scrutiny of large technology companies. Warren  positioned herself as a leader on the issue this year while campaigning  on a plan to break up Big Tech. She has repeatedly called for unwinding [Facebook Inc.](https://www.bloomberg.com/quote/FB:US)’s acquisitions of WhatsApp and Instagram, along with Google’s purchase of YouTube and advertising platform DoubleClick.\\r\\n\\r\\n  \\r\\n\\r\\nIt’s not clear when a bill would be introduced or whether it  would move forward in its current form. Cicilline has said he would not  introduce antitrust legislation until he concludes an antitrust  investigation for the House Judiciary Committee in early 2020.\\r\\n\\r\\n \\r\\n\\r\\nAmy Klobuchar, a Senator from Minnesota who’s also vying for the  Democratic nomination, has pushed legislation covering similar ground.  Klobuchar plans to introduce additional antitrust legislation soon,  according to a person familiar with the matter who wasn’t authorized to  discuss the plans and asked not to be identified.\\r\\n\\r\\nAny proposal would face significant hurdles to becoming law,  and Warren’s version could be particularly problematic because it  promotes the idea that antitrust enforcement is equivalent to being  against big business, said Barak Orbach, a law professor at the  University of Arizona who received a draft of the bill. “The way I read  it is that Elizabeth Warren is trying to make a political statement in  the course of her campaign,” Orbach said. “It’s likely to have negative  effects on antitrust enforcement, so I just don’t see the upside other  than for the campaign.”\\r\\n\\r\\nThe bill proposes a ban on mergers where one company has annual revenue of more $40 billion, or where both companies have sales exceeding $15 billion,  except under certain exceptions, such as when a company is in immediate  danger of insolvency. That would seemingly put a freeze on many  acquisitions for [Apple Inc.](https://www.bloomberg.com/quote/AAPL:US), [Alphabet Inc.](https://www.bloomberg.com/quote/GOOGL:US), Facebook, [Microsoft Corp.](https://www.bloomberg.com/quote/MSFT:US) and dozens of other companies. The bill would also place new limitations on smaller mergers.\\r\\n\\r\\nChris  Sagers, a law professor at Cleveland State University, said the  proposal would serve as an effective check on corporate power. “I don’t  think you’ll have new antitrust policy until Congress says the courts  have incorrectly interpreted the statutes,” he said. “Someone has to do  what Elizabeth Warren is doing.”                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "Buy more during dips if you can, but at least hold.\\r\\n\\r\\nWe just have to hold until they fold. Today's actions by several brokers just show how desperate the hedge funds are getting.\\r\\n\\r\\nHold with your immovable diamond hands for all that you hold dear and we will be breaking Wall Street **TOGETHER** while making gargantuan tendies in the end!\\r\\n\\r\\n**WE LIKE THE STOCK.**\\r\\n\\r\\nComment with brokers that aren't corruptible and that we can move to fast!\\r\\n\\r\\n**YOU CAN STILL BUY ON**  \\r\\n**Fidelity** (10k instant deposit, accounts can be opened quickly)  \\r\\n**Others:** Vanguard, Revolut, TastyWorks, Charles Schwab, TD Ameritrade, Webull, Degiro, Wells Fargo, M1, Public, etc.\\r\\n\\r\\n*Edit*: It seems like TD Ameritrade, Webull, M1 Finance, and Public have removed their restrictions. Brokers are folding to the political support we are receiving.\\r\\n\\r\\n[**http://isthesqueezesquoze.com/**](http://isthesqueezesquoze.com/)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
       "Name: body, Length: 2068, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at body value counts\n",
    "body = reddit_df.body.value_counts()\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPVOTE so everyone sees we got SUPPORT</td>\n",
       "      <td>265029</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/sgoqy8nyt2e61.png</td>\n",
       "      <td>11825</td>\n",
       "      <td>2021-01-29 00:40:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GME YOLO update — Jan 28 2021</td>\n",
       "      <td>230844</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/opzucppb15e61.png</td>\n",
       "      <td>23532</td>\n",
       "      <td>2021-01-29 08:06:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...</td>\n",
       "      <td>204920</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>18318</td>\n",
       "      <td>2021-01-29 00:49:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GME YOLO update — Jan 27 2021 ----------------...</td>\n",
       "      <td>185949</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/a309gkm5yxd61.png</td>\n",
       "      <td>15495</td>\n",
       "      <td>2021-01-28 08:15:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can we all take a moment and appreciate the Mo...</td>\n",
       "      <td>184517</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>7105</td>\n",
       "      <td>2021-01-28 11:57:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   score       subreddit  \\\n",
       "0             UPVOTE so everyone sees we got SUPPORT  265029  wallstreetbets   \n",
       "1                      GME YOLO update — Jan 28 2021  230844  wallstreetbets   \n",
       "2  CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...  204920  wallstreetbets   \n",
       "3  GME YOLO update — Jan 27 2021 ----------------...  185949  wallstreetbets   \n",
       "4  Can we all take a moment and appreciate the Mo...  184517  wallstreetbets   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0                https://i.redd.it/sgoqy8nyt2e61.png         11825   \n",
       "1                https://i.redd.it/opzucppb15e61.png         23532   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         18318   \n",
       "3                https://i.redd.it/a309gkm5yxd61.png         15495   \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...          7105   \n",
       "\n",
       "                  date  \n",
       "0  2021-01-29 00:40:34  \n",
       "1  2021-01-29 08:06:23  \n",
       "2  2021-01-29 00:49:11  \n",
       "3  2021-01-28 08:15:35  \n",
       "4  2021-01-28 11:57:32  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the 'body' column.\n",
    "reddit_df.drop(['body'], axis=1, inplace=True)\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPVOTE so everyone sees we got SUPPORT</td>\n",
       "      <td>265029</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/sgoqy8nyt2e61.png</td>\n",
       "      <td>11825</td>\n",
       "      <td>2021-01-29 00:40:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GME YOLO update — Jan 28 2021</td>\n",
       "      <td>230844</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/opzucppb15e61.png</td>\n",
       "      <td>23532</td>\n",
       "      <td>2021-01-29 08:06:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...</td>\n",
       "      <td>204920</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>18318</td>\n",
       "      <td>2021-01-29 00:49:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GME YOLO update — Jan 27 2021 ----------------...</td>\n",
       "      <td>185949</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/a309gkm5yxd61.png</td>\n",
       "      <td>15495</td>\n",
       "      <td>2021-01-28 08:15:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can we all take a moment and appreciate the Mo...</td>\n",
       "      <td>184517</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>7105</td>\n",
       "      <td>2021-01-28 11:57:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>DID WE MISS THE BOTTOM?! How are people this i...</td>\n",
       "      <td>348</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/g1m6u...</td>\n",
       "      <td>283</td>\n",
       "      <td>2020-04-15 17:03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>Favorite Solar Stock(s)?</td>\n",
       "      <td>348</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/jmct3...</td>\n",
       "      <td>176</td>\n",
       "      <td>2020-11-02 10:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>\"NIO forms battery asset company\"</td>\n",
       "      <td>352</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/id8z3...</td>\n",
       "      <td>102</td>\n",
       "      <td>2020-08-20 23:02:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>Amazon is building a $1.5 billion hub for its ...</td>\n",
       "      <td>349</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/5rghg...</td>\n",
       "      <td>145</td>\n",
       "      <td>2017-02-02 03:35:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>Weed legalized in Canada!</td>\n",
       "      <td>356</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/8skaf...</td>\n",
       "      <td>138</td>\n",
       "      <td>2018-06-21 04:38:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2925 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   score  \\\n",
       "0                UPVOTE so everyone sees we got SUPPORT  265029   \n",
       "1                         GME YOLO update — Jan 28 2021  230844   \n",
       "2     CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...  204920   \n",
       "3     GME YOLO update — Jan 27 2021 ----------------...  185949   \n",
       "4     Can we all take a moment and appreciate the Mo...  184517   \n",
       "...                                                 ...     ...   \n",
       "2920  DID WE MISS THE BOTTOM?! How are people this i...     348   \n",
       "2921                           Favorite Solar Stock(s)?     348   \n",
       "2922                  \"NIO forms battery asset company\"     352   \n",
       "2923  Amazon is building a $1.5 billion hub for its ...     349   \n",
       "2924                          Weed legalized in Canada!     356   \n",
       "\n",
       "           subreddit                                                url  \\\n",
       "0     wallstreetbets                https://i.redd.it/sgoqy8nyt2e61.png   \n",
       "1     wallstreetbets                https://i.redd.it/opzucppb15e61.png   \n",
       "2     wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
       "3     wallstreetbets                https://i.redd.it/a309gkm5yxd61.png   \n",
       "4     wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
       "...              ...                                                ...   \n",
       "2920          stocks  https://www.reddit.com/r/stocks/comments/g1m6u...   \n",
       "2921          stocks  https://www.reddit.com/r/stocks/comments/jmct3...   \n",
       "2922          stocks  https://www.reddit.com/r/stocks/comments/id8z3...   \n",
       "2923          stocks  https://www.reddit.com/r/stocks/comments/5rghg...   \n",
       "2924          stocks  https://www.reddit.com/r/stocks/comments/8skaf...   \n",
       "\n",
       "      num_comments                 date  \n",
       "0            11825  2021-01-29 00:40:34  \n",
       "1            23532  2021-01-29 08:06:23  \n",
       "2            18318  2021-01-29 00:49:11  \n",
       "3            15495  2021-01-28 08:15:35  \n",
       "4             7105  2021-01-28 11:57:32  \n",
       "...            ...                  ...  \n",
       "2920           283  2020-04-15 17:03:23  \n",
       "2921           176  2020-11-02 10:46:49  \n",
       "2922           102  2020-08-20 23:02:48  \n",
       "2923           145  2017-02-02 03:35:04  \n",
       "2924           138  2018-06-21 04:38:32  \n",
       "\n",
       "[2925 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows that have at least 1 null value.\n",
    "reddit_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPVOTE so everyone sees we got SUPPORT-- {'neg': 0.0, 'neu': 0.636, 'pos': 0.364, 'compound': 0.5319}\n"
     ]
    }
   ],
   "source": [
    "# Checking Sentiment Scores\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyzer.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(score)))\n",
    "    \n",
    "sentiment_analyzer_scores('UPVOTE so everyone sees we got SUPPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPVOTE so everyone sees we got SUPPORT</td>\n",
       "      <td>265029</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/sgoqy8nyt2e61.png</td>\n",
       "      <td>11825</td>\n",
       "      <td>2021-01-29 00:40:34</td>\n",
       "      <td>0.5319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GME YOLO update — Jan 28 2021</td>\n",
       "      <td>230844</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/opzucppb15e61.png</td>\n",
       "      <td>23532</td>\n",
       "      <td>2021-01-29 08:06:23</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...</td>\n",
       "      <td>204920</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>18318</td>\n",
       "      <td>2021-01-29 00:49:11</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GME YOLO update — Jan 27 2021 ----------------...</td>\n",
       "      <td>185949</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://i.redd.it/a309gkm5yxd61.png</td>\n",
       "      <td>15495</td>\n",
       "      <td>2021-01-28 08:15:35</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can we all take a moment and appreciate the Mo...</td>\n",
       "      <td>184517</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>7105</td>\n",
       "      <td>2021-01-28 11:57:32</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   score       subreddit  \\\n",
       "0             UPVOTE so everyone sees we got SUPPORT  265029  wallstreetbets   \n",
       "1                      GME YOLO update — Jan 28 2021  230844  wallstreetbets   \n",
       "2  CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...  204920  wallstreetbets   \n",
       "3  GME YOLO update — Jan 27 2021 ----------------...  185949  wallstreetbets   \n",
       "4  Can we all take a moment and appreciate the Mo...  184517  wallstreetbets   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0                https://i.redd.it/sgoqy8nyt2e61.png         11825   \n",
       "1                https://i.redd.it/opzucppb15e61.png         23532   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         18318   \n",
       "3                https://i.redd.it/a309gkm5yxd61.png         15495   \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...          7105   \n",
       "\n",
       "                  date  compound    neg    neu    pos  \n",
       "0  2021-01-29 00:40:34    0.5319  0.000  0.636  0.364  \n",
       "1  2021-01-29 08:06:23    0.4278  0.000  0.679  0.321  \n",
       "2  2021-01-29 00:49:11   -0.5994  0.107  0.893  0.000  \n",
       "3  2021-01-28 08:15:35    0.4278  0.000  0.841  0.159  \n",
       "4  2021-01-28 11:57:32    0.6369  0.000  0.794  0.206  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add VADER metrics to dataframe\n",
    "reddit_df['compound'] = [analyzer.polarity_scores(v)['compound'] for v in reddit_df['title']]\n",
    "\n",
    "reddit_df['neg'] = [analyzer.polarity_scores(v)['neg'] for v in reddit_df['title']]\n",
    "\n",
    "reddit_df['neu'] = [analyzer.polarity_scores(v)['neu'] for v in reddit_df['title']]\n",
    "\n",
    "reddit_df['pos'] = [analyzer.polarity_scores(v)['pos'] for v in reddit_df['title']]\n",
    "\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_groups = reddit_df.groupby(\"subreddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>investing</th>\n",
       "      <td>1779.078014</td>\n",
       "      <td>424.946302</td>\n",
       "      <td>-0.009373</td>\n",
       "      <td>0.080139</td>\n",
       "      <td>0.842621</td>\n",
       "      <td>0.077234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stocks</th>\n",
       "      <td>1405.035533</td>\n",
       "      <td>311.643655</td>\n",
       "      <td>0.038948</td>\n",
       "      <td>0.060024</td>\n",
       "      <td>0.852797</td>\n",
       "      <td>0.087179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wallstreetbets</th>\n",
       "      <td>29348.439664</td>\n",
       "      <td>2753.270724</td>\n",
       "      <td>0.046143</td>\n",
       "      <td>0.066779</td>\n",
       "      <td>0.834423</td>\n",
       "      <td>0.098805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       score  num_comments  compound       neg       neu  \\\n",
       "subreddit                                                                  \n",
       "investing        1779.078014    424.946302 -0.009373  0.080139  0.842621   \n",
       "stocks           1405.035533    311.643655  0.038948  0.060024  0.852797   \n",
       "wallstreetbets  29348.439664   2753.270724  0.046143  0.066779  0.834423   \n",
       "\n",
       "                     pos  \n",
       "subreddit                 \n",
       "investing       0.077234  \n",
       "stocks          0.087179  \n",
       "wallstreetbets  0.098805  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping Vader Scores for each Subreddit\n",
    "reddit_groups.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>does anyone here have friends and family still...</td>\n",
       "      <td>898</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/ef...</td>\n",
       "      <td>609</td>\n",
       "      <td>2019-12-26 05:47:26</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>Jobs growth soars in November as payrolls surg...</td>\n",
       "      <td>905</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/e6...</td>\n",
       "      <td>496</td>\n",
       "      <td>2019-12-07 00:41:05</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>Yale economists argue that \"the most financial...</td>\n",
       "      <td>894</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/en...</td>\n",
       "      <td>400</td>\n",
       "      <td>2020-01-13 05:35:24</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>Amazon earnings beat: $6.04 per share, vs. $5....</td>\n",
       "      <td>897</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/al...</td>\n",
       "      <td>152</td>\n",
       "      <td>2019-02-01 08:04:51</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>U.S. stocks plunge after report that former na...</td>\n",
       "      <td>890</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/7g...</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-12-02 03:34:52</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  score  subreddit  \\\n",
       "1935  does anyone here have friends and family still...    898  investing   \n",
       "1936  Jobs growth soars in November as payrolls surg...    905  investing   \n",
       "1937  Yale economists argue that \"the most financial...    894  investing   \n",
       "1938  Amazon earnings beat: $6.04 per share, vs. $5....    897  investing   \n",
       "1939  U.S. stocks plunge after report that former na...    890  investing   \n",
       "\n",
       "                                                    url  num_comments  \\\n",
       "1935  https://www.reddit.com/r/investing/comments/ef...           609   \n",
       "1936  https://www.reddit.com/r/investing/comments/e6...           496   \n",
       "1937  https://www.reddit.com/r/investing/comments/en...           400   \n",
       "1938  https://www.reddit.com/r/investing/comments/al...           152   \n",
       "1939  https://www.reddit.com/r/investing/comments/7g...           377   \n",
       "\n",
       "                     date  compound    neg    neu    pos  \n",
       "1935  2019-12-26 05:47:26   -0.0258  0.143  0.717  0.139  \n",
       "1936  2019-12-07 00:41:05    0.3818  0.000  0.776  0.224  \n",
       "1937  2020-01-13 05:35:24    0.0460  0.100  0.792  0.108  \n",
       "1938  2019-02-01 08:04:51    0.4404  0.000  0.642  0.358  \n",
       "1939  2017-12-02 03:34:52    0.3400  0.000  0.893  0.107  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df = reddit_df[reddit_df[\"subreddit\"]!=\"stocks\"]\n",
    "reddit_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aboon\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Changing Subreddit values to be 1 if from WSB and 0 if not.\n",
    "reddit_df['subreddit'] = reddit_df['subreddit'].apply(lambda x:1 if x == \"wallstreetbets\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPVOTE so everyone sees we got SUPPORT</td>\n",
       "      <td>265029</td>\n",
       "      <td>1</td>\n",
       "      <td>https://i.redd.it/sgoqy8nyt2e61.png</td>\n",
       "      <td>11825</td>\n",
       "      <td>2021-01-29 00:40:34</td>\n",
       "      <td>0.5319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GME YOLO update — Jan 28 2021</td>\n",
       "      <td>230844</td>\n",
       "      <td>1</td>\n",
       "      <td>https://i.redd.it/opzucppb15e61.png</td>\n",
       "      <td>23532</td>\n",
       "      <td>2021-01-29 08:06:23</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...</td>\n",
       "      <td>204920</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>18318</td>\n",
       "      <td>2021-01-29 00:49:11</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GME YOLO update — Jan 27 2021 ----------------...</td>\n",
       "      <td>185949</td>\n",
       "      <td>1</td>\n",
       "      <td>https://i.redd.it/a309gkm5yxd61.png</td>\n",
       "      <td>15495</td>\n",
       "      <td>2021-01-28 08:15:35</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can we all take a moment and appreciate the Mo...</td>\n",
       "      <td>184517</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>7105</td>\n",
       "      <td>2021-01-28 11:57:32</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   score  subreddit  \\\n",
       "0             UPVOTE so everyone sees we got SUPPORT  265029          1   \n",
       "1                      GME YOLO update — Jan 28 2021  230844          1   \n",
       "2  CLASS ACTION AGAINST ROBINHOOD. Allowing peopl...  204920          1   \n",
       "3  GME YOLO update — Jan 27 2021 ----------------...  185949          1   \n",
       "4  Can we all take a moment and appreciate the Mo...  184517          1   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0                https://i.redd.it/sgoqy8nyt2e61.png         11825   \n",
       "1                https://i.redd.it/opzucppb15e61.png         23532   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         18318   \n",
       "3                https://i.redd.it/a309gkm5yxd61.png         15495   \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...          7105   \n",
       "\n",
       "                  date  compound    neg    neu    pos  \n",
       "0  2021-01-29 00:40:34    0.5319  0.000  0.636  0.364  \n",
       "1  2021-01-29 08:06:23    0.4278  0.000  0.679  0.321  \n",
       "2  2021-01-29 00:49:11   -0.5994  0.107  0.893  0.000  \n",
       "3  2021-01-28 08:15:35    0.4278  0.000  0.841  0.159  \n",
       "4  2021-01-28 11:57:32    0.6369  0.000  0.794  0.206  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>date</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>does anyone here have friends and family still...</td>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/ef...</td>\n",
       "      <td>609</td>\n",
       "      <td>2019-12-26 05:47:26</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>Jobs growth soars in November as payrolls surg...</td>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/e6...</td>\n",
       "      <td>496</td>\n",
       "      <td>2019-12-07 00:41:05</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>Yale economists argue that \"the most financial...</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/en...</td>\n",
       "      <td>400</td>\n",
       "      <td>2020-01-13 05:35:24</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>Amazon earnings beat: $6.04 per share, vs. $5....</td>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/al...</td>\n",
       "      <td>152</td>\n",
       "      <td>2019-02-01 08:04:51</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>U.S. stocks plunge after report that former na...</td>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/7g...</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-12-02 03:34:52</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  score  subreddit  \\\n",
       "1935  does anyone here have friends and family still...    898          0   \n",
       "1936  Jobs growth soars in November as payrolls surg...    905          0   \n",
       "1937  Yale economists argue that \"the most financial...    894          0   \n",
       "1938  Amazon earnings beat: $6.04 per share, vs. $5....    897          0   \n",
       "1939  U.S. stocks plunge after report that former na...    890          0   \n",
       "\n",
       "                                                    url  num_comments  \\\n",
       "1935  https://www.reddit.com/r/investing/comments/ef...           609   \n",
       "1936  https://www.reddit.com/r/investing/comments/e6...           496   \n",
       "1937  https://www.reddit.com/r/investing/comments/en...           400   \n",
       "1938  https://www.reddit.com/r/investing/comments/al...           152   \n",
       "1939  https://www.reddit.com/r/investing/comments/7g...           377   \n",
       "\n",
       "                     date  compound    neg    neu    pos  \n",
       "1935  2019-12-26 05:47:26   -0.0258  0.143  0.717  0.139  \n",
       "1936  2019-12-07 00:41:05    0.3818  0.000  0.776  0.224  \n",
       "1937  2020-01-13 05:35:24    0.0460  0.100  0.792  0.108  \n",
       "1938  2019-02-01 08:04:51    0.4404  0.000  0.642  0.358  \n",
       "1939  2017-12-02 03:34:52    0.3400  0.000  0.893  0.107  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and Y sets\n",
    "y = reddit_df[\"subreddit\"]\n",
    "X = reddit_df.drop(columns=[\"subreddit\",\"title\",\"url\",\"date\",\"compound\",\"neu\",\"neg\",\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Breaking sets into train and test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    987\n",
       "1    953\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# scale data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "0            1       0\n",
       "1            1       0\n",
       "2            1       1\n",
       "3            1       1\n",
       "4            1       0\n",
       "5            1       1\n",
       "6            1       0\n",
       "7            1       0\n",
       "8            1       1\n",
       "9            1       1\n",
       "10           1       1\n",
       "11           1       0\n",
       "12           1       1\n",
       "13           1       0\n",
       "14           1       0\n",
       "15           1       1\n",
       "16           1       1\n",
       "17           1       0\n",
       "18           1       1\n",
       "19           1       0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49072164948453606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Attempt #1 - Add Additional Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 80)                240       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 3,311\n",
      "Trainable params: 3,311\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "number_input_features = X_train_scaled.shape[1]\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "#third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# check structure of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 38.0975 - accuracy: 0.5975\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.7181 - accuracy: 0.7691\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.8841 - accuracy: 0.8353\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3479 - accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9589 - accuracy: 0.8227\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.6844 - accuracy: 0.7966\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.4603 - accuracy: 0.8793\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.2291 - accuracy: 0.7991\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.3457 - accuracy: 0.7924\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.4173 - accuracy: 0.7190\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.9283 - accuracy: 0.6727\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.4142 - accuracy: 0.62 - 0s 1ms/step - loss: 4.4203 - accuracy: 0.7805\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 2.3466 - accuracy: 0.8458\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.5189 - accuracy: 0.9132\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.2946 - accuracy: 0.7338\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7297 - accuracy: 0.8930\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.3421 - accuracy: 0.8734\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2145 - accuracy: 0.8572\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0210 - accuracy: 0.8484\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.9417\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.6891 - accuracy: 0.7247\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 6.1509 - accuracy: 0.7889\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.1346 - accuracy: 0.8828\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2460 - accuracy: 0.9199\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.7819 - accuracy: 0.9172\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 2.1716 - accuracy: 0.8285\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9594 - accuracy: 0.8534\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7065 - accuracy: 0.7912\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.3373 - accuracy: 0.7520\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8237 - accuracy: 0.9448\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.9156\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.3910 - accuracy: 0.8881\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.3058 - accuracy: 0.8885\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 2.1720 - accuracy: 0.7927\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1522 - accuracy: 0.9286\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.9135\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.9338\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.8911\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.9128\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.9245\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.9580\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.9423\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0599 - accuracy: 0.8509\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.8946\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8334 - accuracy: 0.8770\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9562 - accuracy: 0.8950\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.9832: 0s - loss: 0.3349 - accuracy: 0.98\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9703\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9547\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.8685 - accuracy: 0.9203\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.9271\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9668\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 0.9816\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9885\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9795\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.9467\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0519 - accuracy: 0.6291\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9791\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.9593\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9805\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9824\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.9803\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4009 - accuracy: 0.9561\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.9427\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4123 - accuracy: 0.9666\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.9364\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9724\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9872\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9908\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9878\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9863\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9943\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9885\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9861\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9937\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9867\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9935\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9965\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9918\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9885\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8143 - accuracy: 0.8388\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9857\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9933\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9930\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9869\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9828\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9929\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.0547 - accuracy: 0.9895\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9562\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.9975\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9921\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9922\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9937\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.1038 - accuracy: 0.9854\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.0421 - accuracy: 0.9907\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9935\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9930\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9877\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9925\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9913\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 0s - loss: 0.0773 - accuracy: 0.9938\n",
      "Loss: 0.0773346871137619, Accuracy: 0.9938144087791443\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Attempt #2: Adding Neurons in Layers & tanh for relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 90)                450       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 40)                3640      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 5,351\n",
      "Trainable params: 5,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "number_input_features = X_train.shape[1]\n",
    "hidden_nodes_layer1 = 90\n",
    "hidden_nodes_layer2 = 40\n",
    "hidden_nodes_layer3 = 30\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "#third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# check structure of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9687 - accuracy: 0.5801\n",
      "Epoch 2/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.9306\n",
      "Epoch 3/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9883\n",
      "Epoch 4/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9945\n",
      "Epoch 5/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9952\n",
      "Epoch 6/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9959\n",
      "Epoch 7/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9959\n",
      "Epoch 8/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9966\n",
      "Epoch 9/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9966\n",
      "Epoch 10/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9966\n",
      "Epoch 11/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9959\n",
      "Epoch 12/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9966\n",
      "Epoch 13/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 0.9959\n",
      "Epoch 14/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9945\n",
      "Epoch 15/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9966\n",
      "Epoch 16/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.9973\n",
      "Epoch 17/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9966\n",
      "Epoch 18/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9966\n",
      "Epoch 19/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9966\n",
      "Epoch 20/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9966\n",
      "Epoch 21/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9973\n",
      "Epoch 22/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9966\n",
      "Epoch 23/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9973\n",
      "Epoch 24/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.9973\n",
      "Epoch 25/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9973\n",
      "Epoch 26/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9973\n",
      "Epoch 27/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9966\n",
      "Epoch 28/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9966\n",
      "Epoch 29/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 0.9973\n",
      "Epoch 30/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 0.9973\n",
      "Epoch 31/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9966\n",
      "Epoch 32/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.9966\n",
      "Epoch 33/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 0.9966\n",
      "Epoch 34/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 0.9973\n",
      "Epoch 35/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 0.9973\n",
      "Epoch 36/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 0.9973\n",
      "Epoch 37/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 0.9973\n",
      "Epoch 38/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.9973\n",
      "Epoch 39/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.9973\n",
      "Epoch 40/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9973\n",
      "Epoch 41/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.9973\n",
      "Epoch 42/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9973\n",
      "Epoch 43/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9973\n",
      "Epoch 44/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9973\n",
      "Epoch 45/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9973\n",
      "Epoch 46/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.9973\n",
      "Epoch 47/63\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9973\n",
      "Epoch 48/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.9973\n",
      "Epoch 49/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.9973\n",
      "Epoch 50/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.9973\n",
      "Epoch 51/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.9973\n",
      "Epoch 52/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9966\n",
      "Epoch 53/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 0.9973\n",
      "Epoch 54/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9973\n",
      "Epoch 55/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9959\n",
      "Epoch 56/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9973\n",
      "Epoch 57/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.9966\n",
      "Epoch 58/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 0.9973\n",
      "Epoch 59/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9973\n",
      "Epoch 60/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.9973\n",
      "Epoch 61/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 0.9966\n",
      "Epoch 62/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 0.9966\n",
      "Epoch 63/63\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9966\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 0s - loss: 0.0062 - accuracy: 0.9979\n",
      "Loss: 0.006236740853637457, Accuracy: 0.9979381561279297\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optmization Attempt #3 - Add Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 80)                400       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 2,861\n",
      "Trainable params: 2,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "number_input_features = X_train.shape[1]\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# check structure of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "46/46 [==============================] - 0s 865us/step - loss: 0.6942 - accuracy: 0.4675\n",
      "Epoch 2/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6855 - accuracy: 0.5048\n",
      "Epoch 3/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6783 - accuracy: 0.5363\n",
      "Epoch 4/150\n",
      "46/46 [==============================] - 0s 798us/step - loss: 0.6764 - accuracy: 0.5808\n",
      "Epoch 5/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6637 - accuracy: 0.6100\n",
      "Epoch 6/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6621 - accuracy: 0.6252\n",
      "Epoch 7/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6572 - accuracy: 0.6426\n",
      "Epoch 8/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6446 - accuracy: 0.6534\n",
      "Epoch 9/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6498 - accuracy: 0.6314\n",
      "Epoch 10/150\n",
      "46/46 [==============================] - 0s 877us/step - loss: 0.6426 - accuracy: 0.6466\n",
      "Epoch 11/150\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6473 - accuracy: 0.6520\n",
      "Epoch 12/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6478 - accuracy: 0.6375\n",
      "Epoch 13/150\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6483 - accuracy: 0.6503\n",
      "Epoch 14/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6389 - accuracy: 0.6560\n",
      "Epoch 15/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6329 - accuracy: 0.6630\n",
      "Epoch 16/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6456 - accuracy: 0.6420\n",
      "Epoch 17/150\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.6375 - accuracy: 0.6451\n",
      "Epoch 18/150\n",
      "46/46 [==============================] - 0s 754us/step - loss: 0.6339 - accuracy: 0.6649\n",
      "Epoch 19/150\n",
      "46/46 [==============================] - 0s 776us/step - loss: 0.6339 - accuracy: 0.6505\n",
      "Epoch 20/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6338 - accuracy: 0.6534\n",
      "Epoch 21/150\n",
      "46/46 [==============================] - 0s 776us/step - loss: 0.6417 - accuracy: 0.6399\n",
      "Epoch 22/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6387 - accuracy: 0.6552\n",
      "Epoch 23/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6305 - accuracy: 0.6665\n",
      "Epoch 24/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6281 - accuracy: 0.6535\n",
      "Epoch 25/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6389 - accuracy: 0.6484\n",
      "Epoch 26/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6361 - accuracy: 0.6453\n",
      "Epoch 27/150\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6411 - accuracy: 0.6420\n",
      "Epoch 28/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6214 - accuracy: 0.6751\n",
      "Epoch 29/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6347 - accuracy: 0.6637\n",
      "Epoch 30/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6358 - accuracy: 0.6451\n",
      "Epoch 31/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6294 - accuracy: 0.6665\n",
      "Epoch 32/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6385 - accuracy: 0.6299\n",
      "Epoch 33/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6592\n",
      "Epoch 34/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6520\n",
      "Epoch 35/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6497 - accuracy: 0.6369\n",
      "Epoch 36/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6319 - accuracy: 0.6609\n",
      "Epoch 37/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.6663\n",
      "Epoch 38/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6155 - accuracy: 0.6789\n",
      "Epoch 39/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6322 - accuracy: 0.6469\n",
      "Epoch 40/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6122 - accuracy: 0.6827\n",
      "Epoch 41/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6407\n",
      "Epoch 42/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6261 - accuracy: 0.6618\n",
      "Epoch 43/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6255 - accuracy: 0.6701\n",
      "Epoch 44/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6225 - accuracy: 0.6724\n",
      "Epoch 45/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6299 - accuracy: 0.6502\n",
      "Epoch 46/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6566\n",
      "Epoch 47/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6545\n",
      "Epoch 48/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6407 - accuracy: 0.6354\n",
      "Epoch 49/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.6541\n",
      "Epoch 50/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6554\n",
      "Epoch 51/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6296 - accuracy: 0.6447\n",
      "Epoch 52/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6247 - accuracy: 0.6511\n",
      "Epoch 53/150\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6697\n",
      "Epoch 54/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.6532\n",
      "Epoch 55/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.6612\n",
      "Epoch 56/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6235 - accuracy: 0.6744\n",
      "Epoch 57/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6078 - accuracy: 0.6804\n",
      "Epoch 58/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6280 - accuracy: 0.6599\n",
      "Epoch 59/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6223 - accuracy: 0.6548\n",
      "Epoch 60/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6151 - accuracy: 0.6727\n",
      "Epoch 61/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6590\n",
      "Epoch 62/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6282 - accuracy: 0.6562\n",
      "Epoch 63/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6327 - accuracy: 0.6409\n",
      "Epoch 64/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6121 - accuracy: 0.6737\n",
      "Epoch 65/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6172 - accuracy: 0.6677\n",
      "Epoch 66/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6248 - accuracy: 0.6566\n",
      "Epoch 67/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6430 - accuracy: 0.6470\n",
      "Epoch 68/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6252 - accuracy: 0.6615\n",
      "Epoch 69/150\n",
      "46/46 [==============================] - 0s 881us/step - loss: 0.6235 - accuracy: 0.6636\n",
      "Epoch 70/150\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6093 - accuracy: 0.6811\n",
      "Epoch 71/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6261 - accuracy: 0.6626\n",
      "Epoch 72/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6377\n",
      "Epoch 73/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6189 - accuracy: 0.6603\n",
      "Epoch 74/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6263\n",
      "Epoch 75/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.6819\n",
      "Epoch 76/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6046 - accuracy: 0.6736\n",
      "Epoch 77/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6309 - accuracy: 0.6554\n",
      "Epoch 78/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6387 - accuracy: 0.6205\n",
      "Epoch 79/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6208 - accuracy: 0.6700\n",
      "Epoch 80/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6273 - accuracy: 0.6425\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 997us/step - loss: 0.6281 - accuracy: 0.6440\n",
      "Epoch 82/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6693\n",
      "Epoch 83/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6083 - accuracy: 0.6805\n",
      "Epoch 84/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6254 - accuracy: 0.6550\n",
      "Epoch 85/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6227 - accuracy: 0.6614\n",
      "Epoch 86/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6250 - accuracy: 0.6518\n",
      "Epoch 87/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6260 - accuracy: 0.6658\n",
      "Epoch 88/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.6460\n",
      "Epoch 89/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6188 - accuracy: 0.6624\n",
      "Epoch 90/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6160 - accuracy: 0.6692\n",
      "Epoch 91/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6418 - accuracy: 0.6334\n",
      "Epoch 92/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6235 - accuracy: 0.6513\n",
      "Epoch 93/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6239 - accuracy: 0.6531\n",
      "Epoch 94/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6171 - accuracy: 0.6622\n",
      "Epoch 95/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.6560\n",
      "Epoch 96/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6183 - accuracy: 0.6691\n",
      "Epoch 97/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.6586\n",
      "Epoch 98/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6071 - accuracy: 0.6835\n",
      "Epoch 99/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6143 - accuracy: 0.6719\n",
      "Epoch 100/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6142 - accuracy: 0.6703\n",
      "Epoch 101/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6148 - accuracy: 0.6729\n",
      "Epoch 102/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6285 - accuracy: 0.6493\n",
      "Epoch 103/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6316 - accuracy: 0.6400\n",
      "Epoch 104/150\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6175 - accuracy: 0.6693\n",
      "Epoch 105/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6001 - accuracy: 0.6959\n",
      "Epoch 106/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6152 - accuracy: 0.6658\n",
      "Epoch 107/150\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6135 - accuracy: 0.6638\n",
      "Epoch 108/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.6741\n",
      "Epoch 109/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.6777\n",
      "Epoch 110/150\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6743\n",
      "Epoch 111/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.6605\n",
      "Epoch 112/150\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6497\n",
      "Epoch 113/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6089 - accuracy: 0.6784\n",
      "Epoch 114/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.6592\n",
      "Epoch 115/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6202 - accuracy: 0.6619\n",
      "Epoch 116/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.6545\n",
      "Epoch 117/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.6470\n",
      "Epoch 118/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6125 - accuracy: 0.6708\n",
      "Epoch 119/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6251 - accuracy: 0.6576\n",
      "Epoch 120/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6201 - accuracy: 0.6628\n",
      "Epoch 121/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6147 - accuracy: 0.6604\n",
      "Epoch 122/150\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6110 - accuracy: 0.6754\n",
      "Epoch 123/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6162 - accuracy: 0.6683\n",
      "Epoch 124/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6395 - accuracy: 0.6440\n",
      "Epoch 125/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6130 - accuracy: 0.6746\n",
      "Epoch 126/150\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6191 - accuracy: 0.6764\n",
      "Epoch 127/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6216 - accuracy: 0.6625\n",
      "Epoch 128/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6134 - accuracy: 0.6770\n",
      "Epoch 129/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6065 - accuracy: 0.6751\n",
      "Epoch 130/150\n",
      "46/46 [==============================] - 0s 883us/step - loss: 0.6321 - accuracy: 0.6496\n",
      "Epoch 131/150\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6186 - accuracy: 0.6568\n",
      "Epoch 132/150\n",
      "46/46 [==============================] - 0s 877us/step - loss: 0.6049 - accuracy: 0.6718\n",
      "Epoch 133/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6209 - accuracy: 0.6513\n",
      "Epoch 134/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.5946 - accuracy: 0.6984\n",
      "Epoch 135/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6225 - accuracy: 0.6588\n",
      "Epoch 136/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6142 - accuracy: 0.6651\n",
      "Epoch 137/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6205 - accuracy: 0.6570\n",
      "Epoch 138/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6188 - accuracy: 0.6613\n",
      "Epoch 139/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6004 - accuracy: 0.6748\n",
      "Epoch 140/150\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6134 - accuracy: 0.6616\n",
      "Epoch 141/150\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6115 - accuracy: 0.6656\n",
      "Epoch 142/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6268 - accuracy: 0.6459\n",
      "Epoch 143/150\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6122 - accuracy: 0.6608\n",
      "Epoch 144/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6153 - accuracy: 0.6590\n",
      "Epoch 145/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.5977 - accuracy: 0.6771\n",
      "Epoch 146/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6058 - accuracy: 0.6760\n",
      "Epoch 147/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6050 - accuracy: 0.6852\n",
      "Epoch 148/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6185 - accuracy: 0.6576\n",
      "Epoch 149/150\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6208 - accuracy: 0.6482\n",
      "Epoch 150/150\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6178 - accuracy: 0.6548\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "fit_model = nn.fit(X_train, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 0s - loss: 0.6363 - accuracy: 0.6247\n",
      "Loss: 0.6363207101821899, Accuracy: 0.6247422695159912\n"
     ]
    }
   ],
   "source": [
    "# evaluate model using test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Attempt #4: Change Activation Function w/ Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkpoint path and filenames\n",
    "import os\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 80)                400       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 2,861\n",
      "Trainable params: 2,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "number_input_features = X_train.shape[1]\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='tanh'))\n",
    "\n",
    "# check structure of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 890us/step - loss: 0.7689 - accuracy: 0.5290\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6833 - accuracy: 0.5414\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6742 - accuracy: 0.6100\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6622 - accuracy: 0.6144\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6668 - accuracy: 0.6193\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6538 - accuracy: 0.6392\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6519 - accuracy: 0.6296\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6477 - accuracy: 0.6504\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 878us/step - loss: 0.6397 - accuracy: 0.6577\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6464 - accuracy: 0.6446\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6451 - accuracy: 0.6497\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6275 - accuracy: 0.6485\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6472 - accuracy: 0.6428\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6436 - accuracy: 0.6268\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.6411 - accuracy: 0.6463\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 814us/step - loss: 0.6350 - accuracy: 0.6447\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6410 - accuracy: 0.6488\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6522 - accuracy: 0.6401\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6448 - accuracy: 0.6408\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6276 - accuracy: 0.6582\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6327 - accuracy: 0.6610\n",
      "Epoch 22/100\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6431 - accuracy: 0.6875\n",
      "Epoch 00022: saving model to checkpoints\\weights.22.hdf5\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6241 - accuracy: 0.6634\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.6443\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6414\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6652\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.6503\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.6604\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6552\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6275 - accuracy: 0.6444\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6214 - accuracy: 0.6653\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6262 - accuracy: 0.6793\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.6459\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.6741\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.6819\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6396\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.6639\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6330 - accuracy: 0.6546\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6189 - accuracy: 0.6637\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6202 - accuracy: 0.6650\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.6714\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.6632\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.6720\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6120 - accuracy: 0.6777\n",
      "Epoch 44/100\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6119 - accuracy: 0.6875\n",
      "Epoch 00044: saving model to checkpoints\\weights.44.hdf5\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6606\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6269 - accuracy: 0.6301\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6240 - accuracy: 0.6623\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6288 - accuracy: 0.6547\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 970us/step - loss: 0.6309 - accuracy: 0.6443\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6223 - accuracy: 0.6659\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 972us/step - loss: 0.6192 - accuracy: 0.6681\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6148 - accuracy: 0.6733\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6146 - accuracy: 0.6573\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6170 - accuracy: 0.6620\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6241 - accuracy: 0.6713\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 954us/step - loss: 0.6279 - accuracy: 0.6329\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6411 - accuracy: 0.6356\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.65 - 0s 901us/step - loss: 0.6180 - accuracy: 0.6629\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6220 - accuracy: 0.6542\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 860us/step - loss: 0.6305 - accuracy: 0.6518\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6249 - accuracy: 0.6605\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6204 - accuracy: 0.6605\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6250 - accuracy: 0.6603\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6164 - accuracy: 0.6676\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6359 - accuracy: 0.6448\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6299 - accuracy: 0.6443\n",
      "Epoch 66/100\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6066 - accuracy: 0.7188\n",
      "Epoch 00066: saving model to checkpoints\\weights.66.hdf5\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.6661\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6557\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6192 - accuracy: 0.6594\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.6558\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.6581\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6131 - accuracy: 0.6583\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.6472\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6179 - accuracy: 0.6470\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.6594\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6288 - accuracy: 0.6414\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6270 - accuracy: 0.6460\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 975us/step - loss: 0.6309 - accuracy: 0.6496\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 0.6247 - accuracy: 0.6625\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6063 - accuracy: 0.6735\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 860us/step - loss: 0.6214 - accuracy: 0.6594\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6239 - accuracy: 0.6506\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 865us/step - loss: 0.6067 - accuracy: 0.6709\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6272 - accuracy: 0.6521\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6260 - accuracy: 0.6544\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6112 - accuracy: 0.6759\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6184 - accuracy: 0.6606\n",
      "Epoch 87/100\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5906 - accuracy: 0.5938\n",
      "Epoch 00087: saving model to checkpoints\\weights.87.hdf5\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6088 - accuracy: 0.6636\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.6171 - accuracy: 0.6585\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6186 - accuracy: 0.6640\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.6089 - accuracy: 0.6772\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.6244 - accuracy: 0.6516\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6266 - accuracy: 0.6611\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6088 - accuracy: 0.6734\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6152 - accuracy: 0.6604\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.6179 - accuracy: 0.6582\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.6111 - accuracy: 0.6698\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.6224 - accuracy: 0.6552\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6023 - accuracy: 0.6680\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.6034 - accuracy: 0.6656\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 886us/step - loss: 0.6176 - accuracy: 0.6579\n",
      "16/16 - 0s - loss: 0.6465 - accuracy: 0.6103\n",
      "Loss: 0.6465413570404053, Accuracy: 0.6103093028068542\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# create callback that saves weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=1000)\n",
    "\n",
    "# train model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100,callbacks=[cp_callback])\n",
    "\n",
    "# evaluate model using test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
